\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Basics of Reinforcement Learning}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Markov Decision Processes}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Policy Gradient Methods}{section.2}% 4
\BOOKMARK [3][-]{subsubsection.2.2.1}{Policy Gradient Theorem}{subsection.2.2}% 5
\BOOKMARK [3][-]{subsubsection.2.2.2}{Parameter-Based Policy Gradient Methods}{subsection.2.2}% 6
\BOOKMARK [1][-]{section.3}{Reinforcement Learning for Systematic Trading}{}% 7
\BOOKMARK [2][-]{subsection.3.1}{Asset Allocation With Transaction Costs}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.2}{Reinforcement Learning Application}{section.3}% 9
\BOOKMARK [1][-]{section.4}{Python Prototype}{}% 10
\BOOKMARK [1][-]{section.5}{C++ Implementation}{}% 11
\BOOKMARK [2][-]{subsection.5.1}{Environment, Task, Agent and Experiment}{section.5}% 12
\BOOKMARK [2][-]{subsection.5.2}{ARACAgent}{section.5}% 13
\BOOKMARK [1][-]{section.6}{Execution Pipeline}{}% 14
\BOOKMARK [1][-]{section.7}{Numerical Results}{}% 15
\BOOKMARK [2][-]{subsection.7.1}{Synthetic Asset}{section.7}% 16
\BOOKMARK [2][-]{subsection.7.2}{Experimental Setup}{section.7}% 17
\BOOKMARK [2][-]{subsection.7.3}{Convergence}{section.7}% 18
\BOOKMARK [2][-]{subsection.7.4}{Performances}{section.7}% 19
\BOOKMARK [2][-]{subsection.7.5}{Impact of Transaction Costs}{section.7}% 20
\BOOKMARK [1][-]{section.8}{Conclusion}{}% 21
