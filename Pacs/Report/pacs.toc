\select@language {english}
\contentsline {section}{\numberline {1}Introduction}{1}{section.1}
\contentsline {section}{\numberline {2}Basics of Reinforcement Learning}{2}{section.2}
\contentsline {subsection}{\numberline {2.1}Markov Decision Processes}{2}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Policy Gradient Methods}{3}{subsection.2.2}
\contentsline {subsubsection}{\numberline {2.2.1}Policy Gradient Theorem}{4}{subsubsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2}Parameter-Based Policy Gradient Methods}{5}{subsubsection.2.2.2}
\contentsline {section}{\numberline {3}Reinforcement Learning for Systematic Trading}{6}{section.3}
\contentsline {subsection}{\numberline {3.1}Asset Allocation With Transaction Costs}{6}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Reinforcement Learning Application}{8}{subsection.3.2}
\contentsline {section}{\numberline {4}Python Prototype}{9}{section.4}
\contentsline {section}{\numberline {5}C++ Implementation}{10}{section.5}
\contentsline {subsection}{\numberline {5.1}\lstinline {Environment}, \lstinline {Task}, \lstinline {Agent} and \lstinline {Experiment}}{10}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}\lstinline {ARACAgent}}{12}{subsection.5.2}
\contentsline {section}{\numberline {6}Execution Pipeline}{14}{section.6}
\contentsline {section}{\numberline {7}Numerical Results}{14}{section.7}
\contentsline {section}{\numberline {8}Conclusion}{14}{section.8}
