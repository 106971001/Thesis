\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{Style/thesis}

%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\title{Reinforcement Learning For Automated Trading}


\author{%
Pierpaolo G. Necchi\\
Mathematical Engineering\\
Politecnico di Milano\\
Milano, IT 20123 \\
\texttt{pierpaolo.necchi@gmail.com}
}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
	The impact of \emph{Automated Trading Systems} (ATS) on financial markets is growing every year and the trades generated by an algorithm now account for the majority of orders that arrive at stock exchanges. In this paper we explore how to find a trading strategy via \emph{Reinforcement Learning} (RL), a branch of \emph{Machine Learning} (ML) that allows to find an optimal strategy for a sequential decision problem by directly interacting with the environment. We show that the the long-short strategy learned for a synthetic asset, whose price follows a stochastic process with some exploitable patterns, consistently outperforms the market. RL thus shows the potential to deal with many financial problems, that can be often formulated as sequential decision problems. 
\end{abstract}

\input{Sections/1_introduction}
\clearpage
\input{Sections/2_basics_of_reinforcement_learning}
\input{Sections/3_application_to_systematic_trading}
\input{Sections/4_python_prototype}
\input{Sections/5_c++_implementation}
\input{Sections/6_execution_pipeline}
\input{Sections/7_numerical_results}
\input{Sections/8_conclusion}

\subsubsection*{Acknowledgments}
This project has been realized under the supervision of Prof. Marcello Restelli and of Prof. Carlo Sgarra and I would like to thank them for their support. I would also like to thank Matteo Pirotta for his advice on some implementation issues. 

\clearpage
\bibliographystyle{unsrt}
\bibliography{Bibliography/bibliography}


\end{document}