\begin{thebibliography}{10}

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, 2016.

\bibitem{sutton1998introduction}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Introduction to reinforcement learning}, volume 135.
\newblock MIT Press Cambridge, 1998.

\bibitem{szepesvari2010algorithms}
Csaba Szepesv{\'a}ri.
\newblock Algorithms for reinforcement learning.
\newblock {\em Synthesis lectures on artificial intelligence and machine
  learning}, 4(1):1--103, 2010.

\bibitem{wiering2012reinforcement}
Marco Wiering and Martijn Van~Otterlo.
\newblock {\em Reinforcement Learning: State-of-the-Art}, volume~12 of {\em
  Adaptation, Learning, and Optimization}.
\newblock Springer, 1 edition, 2012.

\bibitem{peters2008reinforcement}
Jan Peters and Stefan Schaal.
\newblock Reinforcement learning of motor skills with policy gradients.
\newblock {\em Neural networks}, 21(4):682--697, 2008.

\bibitem{kushner2003stochastic}
Harold Kushner and G~George Yin.
\newblock {\em Stochastic approximation and recursive algorithms and
  applications}, volume~35.
\newblock Springer Science \& Business Media, 2003.

\bibitem{sutton1999policy}
Richard~S Sutton, David~A McAllester, Satinder~P Singh, Yishay Mansour, et~al.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In {\em NIPS}, volume~99, pages 1057--1063, 1999.

\bibitem{baxter2001infinite}
Jonathan Baxter and Peter~L. Bartlett.
\newblock Infinite-horizon policy-gradient estimation.
\newblock {\em Journal of Artificial Intelligence Research}, 15:319--350, 2001.

\bibitem{sehnke2008policy}
Frank Sehnke, Christian Osendorfer, Thomas R{\"u}ckstie{\ss}, Alex Graves, Jan
  Peters, and J{\"u}rgen Schmidhuber.
\newblock Policy gradients with parameter-based exploration for control.
\newblock In {\em Artificial Neural Networks-ICANN 2008}, pages 387--396.
  Springer, 2008.

\bibitem{zhao2011analysis}
Tingting Zhao, Hirotaka Hachiya, Gang Niu, and Masashi Sugiyama.
\newblock Analysis and improvement of policy gradient estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  262--270, 2011.

\bibitem{pybrain2010jmlr}
Tom Schaul, Justin Bayer, Daan Wierstra, Yi~Sun, Martin Felder, Frank Sehnke,
  Thomas R{\"u}ckstie{\ss}, and J{\"u}rgen Schmidhuber.
\newblock {PyBrain}.
\newblock {\em Journal of Machine Learning Research}, 11:743--746, 2010.

\bibitem{joshi2008c++}
Mark~Suresh Joshi.
\newblock {\em C++ design patterns and derivatives pricing}, volume~2.
\newblock Cambridge University Press, 2008.

\bibitem{moody1998performance}
John Moody, L.~Wu, Y.~Liao, and M.~Saffell.
\newblock Performance functions and reinforcement learning for trading systems
  and portfolios.
\newblock {\em Journal of Forecasting}, 17:441--470, 1998.

\bibitem{kamijo1990stock}
Ken'ichi Kamijo and Tetsuji Tanigawa.
\newblock Stock price pattern recognition-a recurrent neural network approach.
\newblock In {\em IEEE 1990 IJCNN International Joint Conference on Neural
  Networks}, 1990.

\bibitem{saad1998comparative}
Emad~W. Saad, Danil~V. Prokhorov, and Donald~C. Wunsch.
\newblock Comparative study of stock trend prediction using time delay,
  recurrent and probabilistic neural networks.
\newblock {\em IEEE Transactions on Neural Networks}, 9(6):1456--1470, 1998.

\bibitem{liang2011stock}
Jiuzhen Liang, Wei Song, and Mei Wang.
\newblock Stock price prediction based on procedural neural networks.
\newblock {\em Adv. Artif. Neu. Sys.}, 2011:1--11, 2011.

\bibitem{deng2016deep}
Yue Deng, Feng Bao, Youyong Kong, Zhiquan Ren, and Qionghai Dai.
\newblock Deep direct reinforcement learning for financial signal
  representation and trading.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2016.

\end{thebibliography}
