\section{Introduction}
\label{sec:introduction}

The trading pit of a stock exchange is often imagined by outsiders as a frenzy place, with telephones constantly ringing and traders shouting orders across the room at a frenetic rhythm. This was probably the reality thirty years ago, when open outcry was still the main communication system between pit traders. Since then the floors have become more and more quiet as the majority of the orders moved to electronic trading systems. Notwithstanding, investment decisions were still made by humans who could now execute their orders without passing through the pit traders. In the last decade, the markets have witnessed the widespread adoption of \emph{Automated Trading Systems} (ATS), that can make investment decisions in a fully automatized way at speeds with orders of magnitude greater than any human equivalent. In 2014, more than $75\%$ of the stock shares traded on United States exchanges were originated from ATS orders and this amount kept growing since then. Quantitative hedge funds, such as Renaissance Technologies, D.E. Shaw, Citadel and many others, are employing mathematicians, physicists and other scientists to develop algorithms able to extract trading signals from large amount of data and automatically trade. These algorithms are typically based on advanced statistics, signal processing, machine learning and other fields of mathematics. However, few of these hedge funds publish their profit-generating ``secret sauce'' and not much can be found in the literature. In this project we develop an automated trading algorithm based on \emph{Reinforcement Learning} (RL), a branch of \emph{Machine Learning} (ML) which has recently been in the spotlight for being at the core of the system who beat the Go world champion in a 5-match series \cite{silver2016mastering}.\\
This document is organized as follows. In Section \ref{sec:basics_reinforcement_learning} we introduce the basic concepts of RL and present two learning algorithms that allow two determine an approximation for the optimal policy of a sequential decision problem. In section \ref{sec:application_to_systematic_trading} we discuss the asset allocation problem from a mathematical point of view and show how these learning algorithms can be applied in this setting. In Section \ref{sec:python_prototype} we start discussing the implementation of the model in Python, which has been used during the prototyping phase. In Section \ref{sec:c++_implementation} we discuss a more efficient C++ implementation. In Section \ref{sec:execution_pipeline} we describe the execution pipeline used to run the learning experiment. In Section \ref{sec:numerical_results} we present the numerical results for a synthetic asset, whose price follows a particular stochastic process. In Section \ref{sec:conclusion} we conclude with some final remarks and we discuss some future research directions. 
