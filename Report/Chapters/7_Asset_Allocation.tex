\chapter{Financial Applications of Reinforcement Learning}
\label{ch:financial_applications_of_reinforcement_learning}

Both in the academia and in the financial industry there has always been a strong interest in developing automated systems able to take financial decisions in the place of humans. The advent of computers made it possible to analyze the huge amount of data available the markets and to discover patterns that could be exploited automatically by a program, in what is known as a statistical arbitrage. In Section  \ref{sec:efficient_market_hypothesis} we briefly discuss the \emph{Efficient Market Hypothesis} (EMH) which states that it is impossible to "beat the market" because stock market efficiency causes existing share prices to always incorporate and reflect all relevant information. However, the success of many quantitative hedge-funds over the years provides strong evidence that real markets are not so efficient as they are often considered in the literature. We thus discuss some weaker versions of market efficiency which should always be kept in mind when trying to develop automated trading systems. In this chapter, out of the many techniques that can be used, we will focus on reinforcement learning. In Section \ref{sec:bibliographical_survey}, we describe the relevant works that can be found in the literature. This presentation will give an idea of the spectrum of financial problems that can be tackled with RL techniques. In Section \ref{sec:asset_allocation_with_transaction_costs}, we present in more detail the problem of asset allocation with transaction costs, which will be used for the numerical applications.

\section{Efficient Market Hypothesis}  
\label{sec:efficient_market_hypothesis}

When trying to forecast future returns of speculative assets, one should always keep in mind the \emph{Efficient Market Hypothesis} (EMH) \cite{timmermann2004efficient}. In its most basic form, the EMH states that asset returns cannot be forecasted, otherwise many investors would exploit them to generate unlimited profits. Such a ``money-machine'' producing unlimited wealth is impossible in a stable economy. This hypothesis seems intuitively sensible, in fact as soon as an inconsistency appears in the market, there is an agent who exploits it and makes the opportunity disappear. Hence, forecasting models ``self-destructs'' in an efficient market which auto-corrects the emerging anomalies. Intellectually, that might appear as the end of the forecasters' ambitions. However this idea is not completely convincing and papers continue to appear attempting to forecast stock returns, usually with very little success. On the other hand, a number of successful stories of quantitative hedge-funds which consistently made profits looking for statistical arbitrages make us doubt the EMH. In the next sections we give more formal definitions of the EMH in its various forms and discuss some of the critics.

\subsection{Formal Definitions of the EMH}
\begin{definition}[Efficient Market Hypothesis]
	A market is efficient with respect to information set $\calF_t$ if it is impossible to make economic profits by trading on the basis of information set $\calF_t$.
\end{definition}
where by economic profits we mean the risk adjusted returns net of all costs. The EMH is in essence an extension of the zero-profit competitive equilibrium condition from the certainty world of classical price theory to the dynamic behavior of prices in speculative markets under conditions of uncertainty \cite{jensen1978some}. The application of the zero profit condition to speculative markets under the assumption of zero storage costs and zero transactions costs gives us the result that asset prices (after adjustment for required returns) will behave as a martingales with respect to the information set $\{\calF_t\}$.\\
Several versions of the EMH have been proposed in the literature depending on the information set considered.
\begin{definition}[Weak Form of the EMH]
	$\calF_t$ represents only the information contained in the past price history of the market as of time $t$. 
\end{definition}

\begin{definition}[Semi-Strong Form of the EMH]
	$\calF_t$ represents all information publicly available at time $t$. 
\end{definition}

\begin{definition}[Strong Form of the EMH]
	$\calF_t$ represents all information (public and private) known to anyone at time $t$	
\end{definition}
Let us notice that it is not usually asserted that a market is efficient with respect to inside information since this information is not widely accessible and hence cannot be expected to be fully incorporated in the
current price. The empirical evidence presented in \cite{malkiel1970efficient} is largely supportive of weak form and semi-strong form efficiency, while \cite{fama1991efficient} reports stronger evidence of predictability in returns based both on lagged values of returns and publicly available information.


\subsection{Critics to the EMH}

It is often argued that there is a ``file drawer'' bias in published studies due to the difficulty associated with publishing empirical studies that find insignificant effects. In studies of market efficiency, a reverse bias may be present. A researcher who genuinely believes he or she has identified a method for predicting the market has little incentive to publish the method in an academic journal and would presumably be tempted to sell it to an investment bank or to an hedge fund.\\
The numerous examples of successful quantitative hedge funds would suggest that it is possible, even if extremely difficult, to identify profitable patterns in market dynamics. Medallion, the flagship fund of Renaissance Technologies, one of the most successful hedge fund ever, returned 39 percent per year on average between the end of 1989 and 2006. Its founder Jim Simons, a mathematician who gave notable contributions to string theory, a code breaker who worked worked at the Pentagonâ€™s Institute for Defense Analyses during the cold war, a lifelong speculator and entrepreneur, assembled one of the most successful and secretive group of quantitative researchers ever. The following is the only information available on its website\footnote{\url{https://www.rentec.com/}} 
\begin{quote}
Renaissance Technologies LLC is an investment management company dedicated to producing superior returns for its clients and employees by adhering to mathematical and statistical methods
\end{quote}
This doesn't shed any light on how RenTech achieves its extraordinary results and the fact that almost nobody leaves the firm made its strategies one of the best-kept secret in the world. For a richer account of this (and other) legendary hedge fund, the reader may refer to \cite{mallaby2010more}.  


\section{Bibliographical Survey}
\label{sec:bibliographical_survey}

Many financial applications can be represented as sequential decision problems and can be naturally tackled with the reinforcement learning techniques presented in the previous chapters. Consider for instance the process of trading, in which an investor tries to select the assets that will perform the better in the future and will allow him to realize a profit. This activity is well depicted ad an online decision problem involving two critical steps of \emph{market representation} and \emph{optimal action execution}.\\
Financial markets are extremely complex systems, typically characterized by a large degree of non-stationarity, non-linearity and low signal-to-noise ratios. The first challenge is thus how to summarize the financial environment or, put in more statistical terms, how to design powerful features to be used as input of predictive models. The search for good indicators has been extensively studied in quantitative finance and econometrics. In particular, \emph{technical analysis} is a security analysis methodology for forecasting the direction of prices through the study of past market data, primarily price and volume \cite{lo2000foundations}. Whether technical analysis actually works is a matter of controversy. Methods vary greatly, and different technical analysts can sometimes make contradictory predictions from the same data. Many investors claim that they experience positive returns, but academic appraisals often find that it has little predictive power. Another issue is that designing hand-crafted features requires a deep knowledge of the financial markets. A solution to this drawback is offered by \emph{Deep Learning} (DL), a branch of machine learning based on a set of algorithms that attempt to model high level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations \cite{Goodfellow-et-al-2016-Book}. In the last years, deep learning has been in the spotlight as its application to fields like computer vision, automatic speech recognition, natural language processing, audio recognition and bioinformatics have produced state-of-the-art results on various tasks. These successes have attracted the interest of the financial community and the literature offers many examples of how deep neural network can be used to predict future prices \cite{kamijo1990stock}, \cite{saad1998comparative}, \cite{liang2011stock} and invest on these forecasts.\\ 
The second challenge is how to select the best possible action based on this representation of the market. This is not a trivial task, as the action selected by the investor may influence the market and modify the opportunities that will be available to him in the future. A simple example of this situation is the phenomenon of slippage, which consists in a loss due to the difference between the expected price of a trade and the price at which the trade is executed. This is common in limit-order books when there is no sufficient liquidity to complete a market order at the best available price and the order ``walks the book'', obtaining progressively worse prices. Another difficulty is that the investor's actions may impact its profits in a non-trivial way. 
For example, frequently changing its positions or entering in short positions will lead to large transaction costs which will undermine the performance of even the most accurate predictive trading strategy, such as those based deep neural networks. Hence, these approaches are typically viable only on long investment horizons as the performances of quickly degrade on shorter horizons because of transaction costs. Therefore, an investor should take into account the dynamic behavior of the market and of the returns he obtains. Reinforcement learning appears as the natural approach to determine the optimal strategy to be followed.\\
In the following sections we briefly present some of the financial applications of reinforcement learning that can be found in the literature. This will give us a better feeling for the inherent difficulties of the financial markets and for how they can be tackled. 

\subsection{Asset Allocation with Transaction Costs}
TODO

\subsection{Optimal Order Execution in Limit-Order Book}
TODO 

\subsection{Optimal Order Allocation Across Dark Pools}
TODO


\section{Asset Allocation with Transaction Costs}
\label{sec:asset_allocation_with_transaction_costs}

The asset allocation problem consists of determining how to dynamically invest
the available capital in a portfolio of different assets in order to maximize
the expected total return or another relevant performance measure. Let us
consider a financial market consisting of $I+1$ different stocks that are
traded only at discrete times $t \in \{0, 1, 2, \ldots\}$ and denote by
${Z}_t = {(Z_t^0, Z_t^1, \ldots, Z_t^I)}^T$ their prices at time $t$.
Typically, $Z_t^0$ refers to a riskless asset whose dynamic is given by $Z_t^0
= {(1 + X)}^t$ where $X$ is the deterministic risk-free interest rate. The
investment process works as follows: at time $t$, the investor observes the
state of the market $S_t$, consisting for example of the past asset prices and
other relevant economic variables, and subsequently chooses how to rebalance
his portfolio, by specifying the units of each stock ${n}_t = {(n_t^0 ,
n_t^1 , \ldots , n_t^I)}^T$ to be held between $t$ and $t+1$. In doing so, he
needs to take into account the transaction costs that he has to pay to the
broker to change his position.  At time $t+1$, the investor realizes a profit
or a loss from his investment due to the stochastic variation of the stock
values. The investorâ€™s goal is to maximize a given performance measure.

\subsection{Reward Function}
Let $W_t$ denote the wealth of the investor at time $t$. The profit realized
between $t$ and $t+1$ is simply given by the difference between the trading
results and the transaction costs payed to the broker. More formally
\begin{equation*}
	\Delta W_{t+1} = W_{t+1} - W_t = \text{NL}_{t+1} - \text{TC}_{t}	
\end{equation*}
where $\text{PNL}_{t+1}$ denotes the profit due to the variation of the
portfolio asset prices between $t$ and $t+1$
\begin{equation*}
	\text{PNL}_{t+1} = {n}_t \cdot \Delta{Z}_{t+1} = \sum^{I}_{i=0} 
	n_t^i (Z_{t+1}^i - Z_t^i) 
\end{equation*}
and $\text{TC}_t$ denotes the fees payed to the broker to change the portfolio
allocation and on the short positions
\begin{equation*}
	\text{TC}_t = \sum^{I}_{i=0} \delta_p^i \left| n_t^i - n_{t-1}^i\right| Z_t^i 
				- \delta_f W_t \ind{{n}_t \neq {n}_{t-1}} 
				- \sum^{I}_{i=0} \delta_s^i {(n_t^i)}^{-} Z_t^i
\end{equation*}
The transaction costs consist of three different components. The first term 
represent a transaction cost that is proportional to the change in value of the 
position in each asset. The second term is a fixed fraction of the total value
of the portfolio which is payed only if the allocation is changed. The last
term represents the fees payed to the broker for the shares borrowed to build a
short position. The portfolio return between $t$ and $t+1$ is thus given by
\begin{equation}\label{eq:portfolio_return}
	X_{t+1} = \frac{\Delta W_{t+1}}{W_t} = \sum^{I}_{i=0} \left[ a_t^i
	X_{t+1}^i - \delta_i \left| a_t^i - \tilde{a}_t^i \right| - \delta_s
	{(a_t^i)}^- \right] - \delta_f \ind{{a}_t \neq \tilde{{a}}_{t-1}}  
\end{equation}
where 
\begin{equation*}
	X_{t+1}^i = \frac{\Delta Z_{t+1}^i}{Z_t^i}
\end{equation*}
is the return of the $i$-th stock between $t$ and $t+1$, 
\begin{equation*}
	a_t^i = \frac{n_t^i Z_t^i}{W_t}
\end{equation*}
is the fraction of wealth invested in the $i$-th stock between time $t$ and
$t+1$ and finally 
\begin{equation*}
	\tilde{a}_t^i = \frac{n_{t-1}^i Z_t^i}{W_t} = \frac{a_{t-1}^i (1+X_t^i)}
	{1 + X_t}
\end{equation*}
is the fraction of wealth invested in the $i$-th stock just before the 
reallocation. We assume that the agent invests all his wealth at each step, so 
that $W_t$ can be also interpreted as the value of his portfolio. This 
assumption leads to the following constraint on the portfolio weights
\begin{equation}
	\sum^{I}_{i=0} a_t^i = 1 \;\;\;\;\; \forall t \in \{0, 1, 2, \ldots\}
\end{equation}
We notice that we are neglecting the typical margin requirements on the short
positions, which would reduce the available capital at time $t$. Considering
margin requirements would lead to a more complex constraint on the portfolio
weights which would be difficult to treat in the reinforcement learning
framework. Plugging this constraint into Eq. (\ref{eq:portfolio_return}), we
obtain
\begin{equation}\label{eq:portfolio_return_benchmark}
	X_{t+1} = X + \sum^{I}_{i=1} a_t^i (X_{t+1}^i - X) - \sum^{I}_{i=0}
	\left[\delta_i \left| a_t^i - \tilde{a}_t^i \right| - \delta_s^i
	{(a_t^i)}^-\right] - \delta_f \ind{{a}_t \neq \tilde{{a}}_{t-1}}   
\end{equation}
which highlights the role of the risk-free asset as a benchmark for the 
portfolio returns. The total profit realized by the investor between $t=0$ and
$T$ is 
\begin{equation*}
	\Pi_T = W_T - W_0 = \sum^{T}_{t=1} \Delta W_t = \sum^{T}_{t=1} W_t X_t  
\end{equation*}
The portfolio return between $t=0$ and $T$ is given by
\begin{equation*}
	X_{0,T} = \frac{W_T}{W_0} - 1 = \prod_{t=1}^T (1+X_t) - 1
\end{equation*}
In order to cast the asset allocation problem in the reinforcement learning
framework, we consider the log-return of the portfolio between $t=0$ and $T$
\begin{equation}
	R_{0,T} = \log \frac{W_T}{W_0} = \sum^{T}_{t=1} \log(1+X_t) = \sum_{t=1}^T
	R_t
\end{equation}
where $R_{t+1}$ is the log-return of the portfolio between $t$ and $t+1$
\begin{equation}
	R_{t+1} = \log \left\{ 1 + \sum^{I}_{i=0} \left[ a_t^i X_{t+1}^i - \delta_i
	\left| a_t^i - \tilde{a}_t^i \right| - \delta_s {(a_t^i)}^- \right] -
	\delta_f \ind{{a}_t \neq \tilde{{a}}_{t-1}}\right\}
\end{equation}
The portfolio return and log-return can be used as the reward function of a
RL algorithm, either in a offline or in an online approach.

\subsection{States}
At each time step, the agent observes the state of the system to  make his decisions. First, we consider the $P+1$ past returns of all risky assets, i.e. $\{X_t, X_{t-1}, \ldots, X_{t-P}\}$. These input variables may be used to construct more complex features for example using some deep learning techniques, such as a deep auto-encoder. In order to properly incorporate the effects of transaction costs into his decision process, the agent must keep track of its current position $\tilde{a}_t$. Finally, we might consider some external variables $Y_t$ that may be relevant to the trader, such as the common technical indicator used in practice. Summing up, we assume that the state of the system is composed in the following way 
\begin{equation}
	S_t = \{X_t, X_{t-1}, \ldots, X_{t-P}, \tilde{a}_t, Y_t, Y_{t-1}, \ldots,
	Y_{t-P}\}
\end{equation}

\subsection{Actions}
The agent, or trading system, only specifies the portfolio weights $a_t = (a_t^0,
\ldots, a_t^I)^T$ and therefore determines the allocation for the time interval
$[t, t+1)$. If we assume that the agent invests all of his capital at each time
step and that short-selling is not allowed, then the portfolio weights should
satisfy, for every $t \in \{0, 1, \ldots\}$, the following constraints
\begin{equation}
	\begin{cases}
		a_t^i \geq 0 \;,\; \forall i \in \{0, \ldots, I\}\\
		\sum^{I}_{i=0} a_t^i = 1 
	\end{cases}
\end{equation}
This constraint can be easily enforced by considering a parametric softmax 
policy. If short-selling is allowed, weights might also be negative. A simple approach is to assume that, for every $t \in \{0, 1, \ldots\}$, the weights satisfy
\begin{equation}
	\begin{cases}
		a_t^i \in \R \;,\; \forall i \in \{1, \ldots, I\}\\
		a_t^0 = 1 - \sum^{I}_{i=1} a_t^i
	\end{cases}
\end{equation}
Since $a_t^0$ is uniquely determined by the other weights, it is enough to
define a policy that specifies the allocation in the risky assets, e.g.\ a
Gaussian policy in $\R^I$. The obvious shortcoming of this approach is that
the agent might enter in huge short positions, which is not realistic. A first
observation is that, if the stochastic policy is concentrated around the
origin, huge long or short positions would have very small probabilities of 
being selected. Moreover, we notice that the agent would pay large fees for 
entering into large short positions, independently of the trading profits. 
Therefore, we expect the agent to learn that short positions are very expensive 
and would therefore try to avoid them.\\
Working in a continuous action space is computationally difficult and only few
reinforcement learning algorithm are well-suited to this setting, e.g. policy
gradient methods. A simpler approach is to reduce the action space to a discrete 
space. For instance, in the two assets scenario we might assume that $a_t \in
\{-1, 0, +1\}$. Thus the agent may be long ($+1$), neutral ($0$) or short
($-1$) on the risky-asset. Working in a discrete action space is more simple,
and standard value-based approaches might also be employed. 
