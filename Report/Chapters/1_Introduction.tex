\chapter{Introduction}

The impact of \gls{ATS} on financial markets is growing every year and the trades generated by an algorithm now account for the majority of orders that arrive at stock exchanges. Investments banks and hedge funds are investing large amount of resources to develop new systems to maximize their profits and stay ahead in the technological race that is taking place in the financial markets. The goal of developing an automated system able to take financial decisions without the need for human supervision is not new. From the Technical Computer System developed by Commodities Corporation in the 1970, to the algorithm that caused Knight Capital Group to lose \$440 millions over few hours in 2012, many have been the attempts to trade on the markets using an algorithm. Typically, these approaches were based on advanced statistical methods and signal processing. However, the recent successes of \gls{AI}, and in particular \gls{DL}, have attracted the interest of the financial community. Many quantitative researchers asked themselves if the techniques that have proved so successful in classifying images or beating Go world champions could perform equally well on financial markets. In this thesis, we explore how to find a trading strategy via \gls{RL}, a branch of \gls{ML} that allows to find an optimal strategy for a sequential decision problem by directly interacting with the environment. In this introductory chapter, we briefly describe the current state of the financial markets, which are increasingly dominated by algorithms, and provide a quick overview of the recent advances of \gls{AI} and the huge impact that these new techniques are having on our day-to-day life. This chapter thus prepare the stage in which we will move during the entire exposition. 

\section{The Computerization of Finance}
The trading pit of a stock exchange is often imagined by outsiders as a frenzy place, with telephones constantly ringing and traders shouting orders across the room at a frenetic rhythm. This was probably the reality around thirty years ago, when open outcry was still the main communication system in the pits. Since then the exchanges have become more and more quiet as the majority of the orders moved to electronic trading platforms, which allow investors to directly execute their orders without passing through the old-fashioned pit traders. In the last decade, the markets have witnessed the widespread adoption of \glsfirst{ATS}, that can make investment decisions in a fully automatized way at speeds with orders of magnitude greater than any human equivalent. Of particular interest nowadays is \gls{HFT}, a type of algorithmic trading characterized by high speeds, high turnover rates, and high order-to-trade ratios that leverages high-frequency financial data and electronic trading tools. While there is no single definition of \gls{HFT}, among its key attributes are highly sophisticated algorithms, specialized order types, co-location, very short-term investment horizons, and high cancellation rates of orders. It has been estimated that in 2014 \gls{HFT} accounted for more than $75\%$ of the stock shares traded on US exchanges.\\
The deep transformation of financial markets has brought algorithmic trading and \gls{HFT} into the spotlight and raised many questions on the actual utility of these technologies. On one side, computerized trading firms have been blamed of causing bouts of extreme volatility and of systematically exploiting the small investors thanks to superior technology, as was claimed for example in \cite{lewis2014flash}. This is typically the position of regulators and politicians, many of whom put the policing of \gls{HFT} at the top of their priorities. On the other hand, the academic literature strongly supports \gls{HFT} having a net positive effect on the markets \cite{brogaard2014high}. The usual argument is that these firms make the markets more stable and efficient, even when volatility surges, by quickly bringing prices back into line. By acting as market makers, \gls{HFT} provides liquidity to the markets and thus reduces bid-ask spreads and transaction costs.\\
To develop the algorithms able to extract trading signals from large amount of noisy data and automatically generate financial decisions, investment banks and quantitative hedge funds are employing mathematicians, physicists and computer scientists. These algorithms are typically based on advanced statistics, signal processing, machine learning and other fields of mathematics. However, few of these firms publish their profit-generating ``secret ingredient'' and not much can be found in the literature. In this thesis we will discuss the application of some state-of-the-art \gls{AI} techniques to determine an automatic and potentially profitable trading strategy.

\section{The New Dawn of Artificial Intelligence}
After many false dawns, \gls{AI} has made extraordinary progress in the past few years, thanks in particular to a versatile technique called \glsfirst{DL}, a form of \glsfirst{ML} that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones. A graph of these hierarchies would be many layers deep \cite{bengio2015deep}. Given enough data, deep neural networks can be trained to successfully complete many different tasks that could previously be done only by humans \cite{economist2016march}. For instance, these methods power Google's search engine, Facebook's automatic photo tagging, Apple's voice assistant, Amazon's shopping recommendations and Tesla's self-driving cars. These techniques have recently been in the spotlight when AlphaGo, an algorithm developed by DeepMind, defeated the 18-time world champion of Go Lee Sedol in a 5-game series \cite{silver2016mastering}. This ancient board game is so complex that computers had not been expected to master it for at least another decade at least. It is not surprising that this rapid sequence of successes have produce a large hype around \gls{ML} and \gls{DL} in particular. Citing John Giannandrea, head of machine-intelligence research at Google, ``what got people excited about this field is that one learning technique, deep learning, can be applied to so many different domains". The financial industry is not excluded.\\
Hedge funds, stung by eight years of underperformance, are latching onto machine learning as a high-tech answer to their woes. But Wall Streetâ€™s heady search for the perfect money machine has collided with a sober reality. The technology, which learns on its own to find investment ideas by hunting through troves of data, requires a heavy commitment of time and money, and a high tolerance for failure, since most algorithms turn out to be duds \cite{bloomberg2016ml}. Financial markets are a particularly difficult challenge for \gls{ML} algorithms and there are infinite ways an algorithm can fail spotting the trading ``signals'' to wager on. While identifying patterns is not particularly hard, finding signals that work reliably in the real world is. Man AHL, a quant unit of Man Group Plc, needed three years of work to gain enough confidence in a machine learning strategy to devote client money to it. This can be hard for the researcher, who will have to stomach and overcome many failures before obtaining positive results. In this thesis, we decided to embark on the difficult journey of developing an automated trading strategy based on \glsfirst{RL}, a general class of algorithms in the field of \gls{ML} that allows an agent to learn how to behave in a stochastic and possibly unknown environment only by trial-and-error.

\section{Structure}
This section outlines the structure of this document, explaining the original contributions that were made in this thesis.\\
In Chapter \ref{ch:discrete_time_stochastic_optimal_control} we introduce the basic concepts of discrete-time stochastic optimal control, which is the standard theoretical framework used to model sequential decision problems. In particular, we describe the central feedback mechanism between a learning agent and a stochastic environment. Finally, we present the less traditional risk-sensitive framework for discrete-time stochastic optimal control.\\
In Chapter \ref{ch:reinforcement_learning} we present the main ideas of reinforcement learning, a general class of algorithms in the field of machine learning that allows an agent to learn how to behave in a stochastic and possibly unknown environment only by trial-and-error. We thoroughly discuss the \gls{RL} problem and its characteristic features. Finally, we give a high-level overview of the different typologies of reinforcement learning algorithms.\\ 
In Chapter \ref{ch:policy_gradient} we give an in-depth presentation of policy gradient algorithms for the risk-neutral control problem. After introducing the key ideas of these methods, we provide a thorough review of the state-of-the-art algorithms that can be found in the literature. In particular, we introduce the main result that will play a crucial role in the rest of this thesis, the policy gradient theorem.\\
In Chapter \ref{ch:risk_sensitive_policy_gradient} we discuss policy gradient methods for the risk-sensitive control problem, which is still an active field of research. In particular, we provide an extension of the policy gradient theorem to the risk-sensitive framework, both in the average reward and in the discounted reward formulations. To the best of our knowledge, this is the first time that a risk-sensitive policy gradient theorem is derived for a general discounted Markov decision process.\\
In Chapter \ref{ch:parameter_based_policy_gradient} we propose an original parameter-based version of the policy gradient theorem, both for the risk-neutral and the risk-sensitive formulation. These theorems allow to derive efficient online learning algorithms similar in spirit to the well-known \gls{PGPE} algorithm, which was originally conceived only for episodic environments. Moreover, these new algorithms can be easily enhanced using a critic or the natural policy gradient idea. This chapter undoubtedly represents the most innovative contribution of this thesis.\\ 
In Chapter \ref{ch:financial_applications_of_reinforcement_learning}, after a brief discussion about why finance represents an extremely challenging field of research, we provide a bibliographical survey of successful applications of \gls{RL} techniques to financial problems. In particular, we focus on the asset allocation problem with transaction cost, which is used as a test case for the numerical application of the learning algorithms proposed in the previous chapters.\\
In Chapter \ref{ch:numerical_results} we present the numerical results for the asset allocation problem. We show that the learning algorithms proposed in the previous chapters perform extremely well on synthetic data. On the other hand, the algorithms encounter more difficulties on historical data and we try to provide an explanation for this behavior.\\
Chapter \ref{ch:conlusions} summarizes the contributions of this thesis to the reinforcement learning literature and presents some interesting ideas for further developments and future work.\\
Given the complexity of financial markets and the ambitious goal of this thesis, success can not be a-priori guaranteed. In this case, the journey matters more than the arrival, as this thesis will allow us to explore these fascinating and current techniques that are revolutionizing the world.  


