\chapter{Numerical Results for the Asset Allocation Problem}
\label{ch:numerical_results}

In this chapter we present the numerical results of some of the policy gradient algorithms discussed in Chapter \ref{ch:policy_gradient} for the asset allocation problem. Two different type of markets are analyzed: a market with only one risky asset and a market where multiple risky assets are available, for which finding a trading strategy is more difficult since the state and action spaces are much larger. The learning algorithms are first applied both in their risk-neutral version and risk-sensitive formulation to synthetically generated data, which present profitably tradable features. Once the behavior of these algorithms is validated in this controlled environment, the application on historical price series is considered. 

\section{Synthetic Risky Asset}
\label{sec:synthetic_risky_asset}
To test the different reinforcement learning methods in a controlled environment, we generated log-price series for the risky asset as random walks with autoregressive trend processes. The two-parameter model is thus given by
\begin{equation*}
	\begin{split}
		z_t &= z_{t-1} + \beta_{t-1} + \kappa \epsilon_t\\
		\beta_t &= \alpha \beta_{t-1} + \nu_t\\
	\end{split}
\end{equation*}
We then define the synthetic price series as
\begin{equation*}
	Z_t = \exp\left(\frac{z_t}{\max_t z_t - \min_t z_t}\right)
\end{equation*}
This model is often taken as a benchmark test in the automated trading literature, see for instance \cite{moody1998performance}, because the price series generated in this way present some patterns that can be profitably exploited. Moreover the model is stationary and therefore the policy learned on the training set should generalize well on the test set, also known as backtest in the financial jargon. Thus we would expect our learning algorithms to perform well on this test case. If this wasn't the case, we should go back and improve the learning algorithms.\\
In this setting, we compare three the results of three long-short strategies obtained with \gls{ARAC}, \gls{PGPE} and \gls{NPGPE} in both the risk-neutral and risk-sensitive framework. This means that the agent can either go long on the risky asset (i.e. $a_t^1 = 1$) or short the security (i.e. $a_t^1 = -1$) and invest the proceedings in the risk-less asset. Given the current conditions of the financial markets, we always assume a risk-free rate $X = 0$. Let us describe in more detail the the choice we made for each of the algorithms. 

\subsection{Specifications of the Learning Algorithms}
Let us detail the choice of the parametric policies selected for each learning algorithm.  

\paragraph{ARAC} 
We considered a Boltzmann exploration policy on the two actions $a_t^1 \in \{-1, 1\}$ and a linear critic in which the features coincide with the agent's observation of the system state. This critic is extremely simple and there is surely some work to be done to improve it. 

\paragraph{PGPE}
We considered a binary deterministic controller 
\begin{equation*}
	F_\theta(s) = \sign(\theta \cdot s)
\end{equation*}
where the parameters and the state also include a bias term. The controller parameters are sampled from a multi-variate Gaussian distribution
\begin{equation*}
	\theta \sim \calN(\mu, \diag(\sigma))
\end{equation*}  

\paragraph{NPGPE}
We used the same controller as for \gls{PGPE} but we assumed that the controller parameters are sampled from a Gaussian distribution parameterized by its mean and Cholesky factor
\begin{equation*}
	\theta \sim \calN(\mu, C^T C)
\end{equation*}  


\subsection{Experimental Setup}   
All the algorithms were tested on the same price series of size $9000$, generated from the process described above using $\alpha = 0.9$ and $\kappa = 3$. The learning process consisted of $1000$ training epochs on the first $7000$ days of the series with a learning rate that decreased at each epoch according to a polynomial schedule. The trained agents were subsequently backtested on the final $2000$ days, during which the agents kept learning online in order to try to adapt to the changing environment. Since the price series is generated using a stationary model, it is not necessary to backtest the algorithm using the rolling-window approach typically employed in practice. The results that we present are the average of $10$ independent experiments that used slightly different random initialization of the policy parameters.   

\subsection{Risk-Neutral Framework}
\subsubsection{Convergence}
\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/6_0_single_synthetic_neutral_convergence}
	\caption[Risk-neutral learning process for one synthetic risky asset.]{Risk-neutral learning process for the asset allocation problem with one synthetic risky asset.}
	\label{fig:single_synthetic_neutral_convergence}
\end{figure}
Let us first discuss the case with no transaction costs. Figure \ref{fig:single_synthetic_neutral_convergence} shows the learning curves for the three risk-neutral algorithms in terms of average daily reward, which is the quantity being maximized by the algorithms, the daily reward standard deviation and the annualized Sharpe ratio. The first thing we observe is the \gls{ARAC} algorithm seems not to be improving the trading strategy as the training epochs go by. The average reward obtained is close to zero and will be surely be negative once transaction costs are introduced. On the other hand, \gls{PGPE} and \gls{NPGPE} show very similar behaviors and quickly converge to a profitable strategy. It is interesting to notice that these algoriths also manage to strongly decrease the variance of the rewards obtained, leading to a strong improvement in the Sharpe ratio. Even if the algorithms are risk-neutral, they manage to improve a risk-senitive measure at the same time of the average reward. This might be simply a peculiarity of the very simple model assumed for the synthetic risky asset. Moreover, since the price process is stationary, the trading strategy learned on the training set perfectly generalizes to the test set. 

\subsubsection{Performances}
Figure \ref{fig:single_synthetic_neutral_performance} compares the backtest performances of the three learned policies and a Buy and Hold strategy, which simply consists in investing all the available capital in the risky asset. Let us repeat that the solid lines are the averages of $10$ independent experiments, which allows us to determine the $95\%$ confidence intervals represented with the dashed lines. We clearly see that \gls{NPGPE} and \gls{PGPE} easily beat the market, realizing a total profit of $363.43\%$ and $352.83\%$ respectively against the $7.81\%$ profit of the Buy and Hold strategy over the same period. We notice that the natural gradient technique allows to achieve higher profits on average with a smaller variance in the outcomes.  
\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\textwidth]{Images/6_1_single_synthetic_neutral_performance}
	\caption[Backtest performance with one synthetic risky asset.]{Backtest performance of trained trading systems for the asset allocation problem with one synthetic risky asset.}
	\label{fig:single_synthetic_neutral_performance}
\end{figure}
Table \ref{tab:single_synthetic_neutral_performance} reports more performance statistics for the trading strategies averaged over the independent experiments. We remark that \gls{PGPE} and \gls{NPGPE} beat the simple Buy and Hold strategy with respect to all measures, impressively achieving the 100\% of profitable years and consecutive 12 months periods. These statistics confirm that \gls{ARAC} is not able to detect the profitable patterns in the synthetic price series and the learned strategy is close to randomness, with a 50\% probability of reallocation (i.e. a coin flip). On the other hand, \gls{PGPE} and \gls{NPGPE} presents much lower reallocation frequencies. This seems promising for dealing with transaction costs, which penalize reallocations and short positions. In the next section we analyze in detail how to behavior of the learned strategies change with the introduction of transaction costs. 


\begin{table}[t!]
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
 & \multicolumn{1}{c}{Buy and Hold} & \multicolumn{1}{c}{ARAC} & \multicolumn{1}{c}{NPGPE} & \multicolumn{1}{c}{PGPE} \\ \midrule
Total Return      & 7.81\%       & -1.00\%  & 363.43\% & 352.83\% \\
Daily Sharpe      & 0.27         & -0.06    & 5.39     & 5.30     \\
Monthly Sharpe    & 0.19         & -0.10    & 3.57     & 3.49     \\
Yearly Sharpe     & 0.23         & -0.11    & 1.96     & 1.84     \\
Max Drawdown      & -22.35\%     & -13.29\% & -2.72\%  & -2.96\%  \\
Avg Drawdown      & -1.75\%      & -4.44\%  & -0.42\%  & -0.42\%  \\
Avg Up Month      & 2.87\%       & 1.03\%   & 2.82\%   & 2.79\%   \\
Avg Down Month    & -2.58\%      & -1.08\%  & -0.64\%  & -0.76\%  \\
Win Year \%       & 40.00\%      & 44.00\%  & 100.00\% & 100.00\% \\
Win 12m \%        & 56.36\%      & 47.64\%  & 100.00\% & 100.00\% \\
Reallocation Freq & 0.00\%       & 49.58\%  & 17.97\%  & 14.75\%  \\
Short Freq        & 0.00\%       & 49.84\%  & 49.83\%  & 42.50\%  \\ \bottomrule
\end{tabular}
\caption[Backtest statistics for risk-neutral learning with one synthetic risky asset.]{Backtest statistics of the risk-neutral trading strategies for the asset allocation problem with one synthetic risky asset. \emph{Total Return} is the cumulative return obtained following the strategy. \emph{Daily Sharpe} is the daily Sharpe ratio, annualized. \emph{Monthly Sharpe} is the monthly Sharpe ratio, annualized. \emph{Yearly Sharpe} is the yearly Sharpe ratio. \emph{Max Drawdown} is the maximum drawdown observed, i.e. the maximum loss from a peak to a trough of a portfolio, before a new peak is attained. \emph{Avg Drawdown} is the average drawdown observed, i.e. the average loss from a peak to a through of a portfolio. \emph{Avg Up Month} is the average profit on a positive month. \emph{Avf Down Month} is the average loss on a negative month. \emph{Win Year \%} is the percentage of positive years. \emph{Win 12\%} is the percentage of profitable consecutive 12 months. \emph{Reallocation Freq} is the frequency with which the agent changes its position. \emph{Short Freq} is the frequency with which the agent shorts the risky asset.}
\label{tab:single_synthetic_neutral_performance}
\end{table}

\subsubsection{Impact of Transaction Costs}
In the algorithmic trading literature there are many examples of strategies based on the prediction of future rewards starting from more or less complex indicators. However, the performances of these methods quickly degrade when transaction costs for changing the portfolio composition or for shorting a security are considered. Indeed, these methods simply invest based on the prediction of the future returns, without explicitly taking into account transaction costs. On the other hand, reinforcement learning algorithms should learn to avoid frequent reallocations or shorts thanks to the feedback mechanism between the learning agent and the system, thus generating better trading performances. In this section we analyze how the strategies learned by \gls{PGPE} and by \gls{NPGPE} change when gradually increasing the proportional transaction costs and the short-selling fees. Intuitively, we expect a progressive reduction of the frequency of reallocation and of shorting the risky asset.\\
Figure \ref{fig:impact_transaction_costs} shows the impact of proportional transaction costs on the trading strategies learned by \gls{PGPE} and by \gls{NPGPE}. 
\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/6_2_impact_transaction_costs}
	\caption[Proportional transaction costs and risk-neutral strategies.]{Impact of proportional transaction costs on the trading strategies learned by PGPE and NPGPE.}
	\label{fig:impact_transaction_costs}
\end{figure}
As expected, the frequency of reallocation for both strategies quickly decreases to zero as the transaction costs increase, converging to the profitable buy and hold strategy. Both algorithms are able to identify reallocation as the cause for lower rewards and to subsequently reduce the rate of reallocation, managing to outperform the naive buy and hold strategy despite of transaction costs.\\
Figure \ref{fig:impact_short_selling_fees} shows the impact of short-selling fees on the trading strategies learned by \gls{PGPE} and \gls{NPGPE}. Both algorithms behave as expected, displaying a progressive reduction of the frequency of short positions as the fees increase. For large values of short-selling fees, both strategies converge to the profitable buy and hold strategy, which completely avoids paying the fees. However, \gls{NPGPE} displays a different convergence pattern compared to the one for proportional transaction costs. In this case, the algorithm shows a threshold effect with the short selling frequency remaining almost constant for small fees, then suddenly dropping to zero if the fee exceeds a certain amount. This behavior is sensible given that, for small amount of fees, shorting may still be profitable. On the other hand, going long will certainly produce a loss. We expect that this pattern will disappear if we allowed the agent to stay neutral, only investing in the risk-free asset. \begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/6_3_impact_short_selling_fees}
	\caption[Short-selling fees and risk-neutral strategies.]{Impact of short-selling fees on the trading strategies learned by PGPE and NPGPE.}
	\label{fig:impact_short_selling_fees}
\end{figure}

\subsection{Risk-Sensitive Framework}
In this section we present the results in the risk-sensitive framework, in which the learning algorithms optimize the Sharpe ratio of the policy. Figure \ref{fig:single_synthetic_sensitive_convergence} shows the learning curves for the three risk-sensitive algorithms \gls{RSPGPE} and \gls{RSNPGPE}. We observe that the natural-gradient algorithm converges to a larger Sharpe ratio compared to the non-natural algorithm, which converges to a suboptimal policy. Moreover, the learning process for \gls{RSPGPE} is characterized by a much larger variance which prevents the algorithm to converge to the same strategy learned by \gls{RSNPGPE}. Surprisingly, the strategies learned by the risk-sensitive algorithms have smaller Sharpe ratio than those learned in the risk-neutral version, in which we don't explicitly control risk. We still don't have a clear explanation for this counter-intuitive behavior. A first hypothesis is that, for the stationary dynamics considered to generate the price series, the optimal policy in the risk-neutral sense also minimize risk, but directly optimizing the Sharpe ratio is more difficult as more parameters and noise are involved in the learning process. Further research should be carried out to investigate this issue in more depth. Figure \ref{fig:single_synthetic_sensitive_performance} shows the backtest performances for the risk-sensitive trading strategies, both outperforming the simple buy-and-hold strategy. Again, we remark that \gls{RSNPGPE} is characterized by a much smaller variance, which leads to more stable results. More statistics are reported in Table \ref{tab:single_synthetic_sensitive_performance}. In particular, we notice that the policy learned by \gls{PGPE} takes much less short positions, which may negatively impact the performance of the strategy.

\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/8_4_single_synthetic_sensitive_convergence}
	\caption[Risk-sensitive learning process for one synthetic risky asset.]{Risk-sensitive learning process for the asset allocation problem with one synthetic risky asset.}
	\label{fig:single_synthetic_sensitive_convergence}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[width=1.0\textwidth]{Images/8_5_single_synthetic_sensitive_performance}
	\caption[Backtest performance with one synthetic risky asset.]{Backtest performance of the risk-sensitive trading strategies for the asset allocation problem with one synthetic risky asset.}
	\label{fig:single_synthetic_sensitive_performance}
\end{figure}

\begin{table}[h!]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
                  & \multicolumn{1}{c}{Buy and Hold} & \multicolumn{1}{c}{RSPGPE} & \multicolumn{1}{c}{RSNPGPE} \\ \midrule
Total Return      & 7.81\%                           & 167.00\%                   & 209.89\%                    \\
Daily Sharpe      & 0.27                             & 2.96                       & 3.86                        \\
Monthly Sharpe    & 0.19                             & 1.92                       & 2.83                        \\
Yearly Sharpe     & 0.23                             & 1.01                       & 1.66                        \\
Max Drawdown      & -22.35\%                         & -7.48\%                    & -4.20\%                     \\
Avg Drawdown      & -1.75\%                          & -0.78\%                    & -0.50\%                     \\
Avg Up Month      & 2.87\%                           & 2.69\%                     & 2.34\%                      \\
Avg Down Month    & -2.58\%                          & -1.14\%                    & -0.88\%                     \\
Win Year \%       & 40.00\%                          & 80.00\%                    & 100.00\%                    \\
Win 12m \%        & 56.36\%                          & 90.91\%                    & 100.00\%                    \\
Reallocation Freq & 0.00\%                           & 20.24\%                    & 33.56\%                     \\
Short Freq        & 0.00\%                           & 27.98\%                    & 47.79\%                     \\ \bottomrule
\end{tabular}
\caption[Backtest statistics for risk-sensitive learning with one synthetic risky asset.]{Backtest statistics of the risk-sensitive trading strategies for the asset allocation problem with one synthetic risky asset.}
\label{tab:single_synthetic_sensitive_performance}
\end{table}
\clearpage
\subsubsection{Risk-Neutral vs. Risk-Sensitive}
A question that naturally arises is if the trading strategies learned by \gls{NPGPE} in the risk-neutral and risk-sensitive frameworks are actually different. The backtest statistics for the two strategies are reported in Table \ref{tab:comparison_NPGPE}. Again, we point out the counter-intuitive fact that risk-neutral version produces higher Sharpe ratios, even if it is not the quantity directly being optimized. The most interesting feature is the different behavior of the two policies in terms of reallocation and short-selling frequencies. The risk-sensitive policy reshuffle the portfolio more frequently than the risk-neutral policy, although resorting less often to short positions. This means that \gls{RSNPGPE} holds the short positions for shorter periods of time. This could be the reason why the risk-sensitive strategy underperforms the risk-neutral one. This analysis shows that the policies learned by the two algorithms are actually different.

\begin{table}[t!]
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
                  & \multicolumn{1}{c}{NPGPE} & \multicolumn{1}{c}{RSNPGPE} \\ \midrule
Total Return      & 363.43\%                  & 209.89\%                    \\
Daily Sharpe      & 5.39                      & 3.86                        \\
Monthly Sharpe    & 3.57                      & 2.83                        \\
Yearly Sharpe     & 1.96                      & 1.66                        \\
Max Drawdown      & -2.72\%                   & -4.20\%                     \\
Avg Drawdown      & -0.42\%                   & -0.50\%                     \\
Avg Up Month      & 2.82\%                    & 2.34\%                      \\
Avg Down Month    & -0.64\%                   & -0.88\%                     \\
Win Year \%       & 100.00\%                  & 100.00\%                    \\
Win 12m \%        & 100.00\%                  & 100.00\%                    \\
Reallocation Freq & 17.97\%                   & 33.56\%                     \\
Short Freq        & 49.83\%                   & 47.79\%                     \\ \bottomrule
\end{tabular}
\caption[Risk-neutral vs. risk-sensitive for a synthetic asset.]{Comparison of NPGPE and RSNPGPE for the asset allocation problem with one synthetic risky asset.}
\label{tab:comparison_NPGPE}
\end{table}

\subsubsection{Impact of Transaction Costs}
Once again we analyze the sensitivity of the trading strategies learned by \gls{RSPGPE} and \gls{RSNPGPE} with respect to transaction costs and short-selling fees. Intuitively, as the fees increase we expect a progressive reduction of the frequency of reallocation and of shorting the risky asset.\\
Figures \ref{fig:8_6_impact_transaction_costs_RS} and \ref{fig:8_7_impact_short_selling_fees_RS} show the impact of proportional transaction costs and short-selling fees respectively on the trading strategies learned: we observe that \gls{RSNPGPE} quickly converge to the profitable Buy and Hold strategy in both situations. On the other hand, \gls{RSPGPE} reduces the reallocation and the short-selling frequencies but not fast enough to avoid a loss for large fees and consequently underperforming the Buy and Hold strategy. This behavior could be due to the large variance that characterizes \gls{RSPGPE}.

\begin{figure}[t!]
\centering
\includegraphics[height=6cm,width=1\linewidth]{Images/8_6_impact_transaction_costs_RS}
\caption[Proportional transaction costs and risk-sensitive strategies.]{Impact of proportional transaction costs on the trading strategies learned by RSPGPE and RSNPGPE.}
\label{fig:8_6_impact_transaction_costs_RS}
\end{figure}

\begin{figure}[t!]
\centering
\includegraphics[height=6cm,width=1\linewidth]{Images/8_7_impact_short_selling_fees_RS}
\caption[Short-selling fees and risk-sensitive strategies.]{Impact of short-selling fees on the trading strategies learned by RSPGPE and RSNPGPE.}
\label{fig:8_7_impact_short_selling_fees_RS}
\end{figure}

\clearpage
\section{Historical Risky Asset}
In this section we discuss the attempt to apply the algorithms above to an historical price series. As a test case, we considered a Banca Monte dei Paschi di Siena (BMPS IM) stock as the risky asset. The experimental setup is the following: the learning algorithms presented above have been trained during 5000 epochs over a period of 1000 days. Then, the performance of the learned trading strategy has been assessed on the following 100 days. As an alternative, we could have employed a more standard ``rolling-window'' backtesting procedure.\\
In this case, the algorithms perform poorly and are not able to identify a profitable trading strategy. In some measure, this was expected given the simplicity of the parametric policy considered. When working on historical price series, there are multiple challenges to be addressed. First, it is not clear if the price series contains some patterns that could be traded profitably. This is the central issue of the \gls{EMH} which was discussed in Section \ref{sec:efficient_market_hypothesis}. Now, even if the prices contained a certain degree of predictability, the parametric policy should be sufficiently expressive to capture these patterns. This is clearly an issue of the current state of work, as the policy considered here is so simple that it would be surprising if it managed to capture a profitably tradable structure in the prices of a liquid stock. A possible development this work would be to employ a much more complex parametric policy, such as a neural network, in order to automatically extract more powerful features from the raw price series. Another related issue is the signal-to-noise ratio of financial time-series. As the policy is updated online, too much noise could mislead the policy gradient method and prevent its convergence.

\subsection{Risk-Neutral Framwork}
These seems to be the issue in the application of the risk-neutral algorithms developed above to the historical data considered. As showed in Figure \ref{fig:8_8_rn_learning_process_historical}, the policy gradient methods fail to converge and the learning curves appear to be dominated by noise. Figure \ref{fig:8_9_single_hist_neutral_performance} shows the average profits generated by the learned strategies on the backtest set in 10 independent experiments. We see that on average the strategies learned with the \gls{ARAC} and \gls{NPGPE} algorithms slightly overperform the simple Buy and Hold strategy. However, the noise is so large that we cannot conclude that the learned strategies are actually better than the Buy and Hold. In addition, since the stock price remains almost flat during the test period a purely random trading strategy would not perform much differently than the Buy and Hold strategy. We suspect that the strategies learned would underperform in a more trending situation. Table \ref{tab:single_historical_neutral_performance} reports a breakdown of the performance measures of the learned strategies on the backtest set. Again, we observe that the \gls{ARAC} algorithm has a reallocation frequency of around 50\%, which reinforce our suspicion that this strategy actually consists in a coin flip. 

\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/8_8_single_hist_neutral_convergence}
	\caption[Risk-neutral learning process for the historical risky asset.]{Risk-neutral learning process for the asset allocation problem with an historical risky asset.}
	\label{fig:8_8_rn_learning_process_historical}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/8_9_single_hist_neutral_performance}
	\caption[Backtest performance with one historical risky asset.]{Backtest performance of the trading systems learned for the asset allocation problem with one historical risky asset.}
	\label{fig:8_9_single_hist_neutral_performance}
\end{figure}

\begin{table}[t!]
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
                  & Buy and Hold & ARAC     & NPGPE    & PGPE     \\ \midrule
Total Return      & 3.29\%       & 7.68\%   & 4.11\%   & -11.72\% \\
Daily Sharpe      & 0.48         & 0.79     & 0.55     & -1.37    \\
Monthly Sharpe    & -0.25        & -0.48    & -0.33    & -2.38    \\
Max Drawdown      & -14.68\%     & -12.33\% & -12.36\% & -20.46\% \\
Avg Drawdown      & -6.90\%      & -7.15\%  & -5.12\%  & -9.61\%  \\
Avg Up Month      & 4.43\%       & 8.27\%   & 3.66\%   & 3.02\%   \\
Avg Down Month    & -2.65\%      & -2.49\%  & -4.00\%  & -5.98\%  \\
Reallocation Freq & 0.00\%       & 50.20\%  & 19.39\%  & 23.47\%  \\
Short Freq        & 0.00\%       & 49.80\%  & 19.80\%  & 38.40\%  \\ \bottomrule
\end{tabular}
\caption[Backtest statistics for risk-neutral learning with one historical risky asset.]{Backtest statistics of the risk-neutral trading strategies for the asset allocation problem with one historical risky asset.}
\label{tab:single_historical_neutral_performance}
\end{table}
\clearpage

\subsection{Risk-Sensitive Framework}
When applied to the historical data, the risk-sensitive algorithms shows a quite different behavior compared to the risk-neutral methods. Figure \ref{fig:8_10_rs_learning_process_historical} shows the learning curves of the algorithms during the different training epochs. While the \gls{RSPGPE} algorithms seems not to improve the policy over time, the policy learned with the \gls{RSNPGPE} algorithm clearly improves with the training epochs and achieves a positive Sharpe ratio. This means that the simple autoregressive controller considered is able to capture some patterns in the training set which leads to positive performance. However it is not guaranteed that what is learned on the training set will hold during the backtest. This is exactly the situation as showed in Figure \ref{fig:8_11_single_hist_sensitive_performance}. Indeed, we remark that the policy learned by the \gls{RSNPGPE} algorithm, although producing a profit on the training set, clearly underperforms the naive Buy and Hold strategy in the backtest. We conclude that the pattern learned in the training set does not generalize to the backtest set. This phenomenon could be seen as a form of overfitting which, however, is not due to the choice of an over-complicated parametric policy (it is clearly not the case here), but to the inconsistence between the training set and the backtest set. This is typical of financial time series, which are often characterized by a strong non-stationarity. For this reason, even if the controller is able to identify a signal in the training set, it is not guaranteed that this signal will persist in the backtest set. Even if the risk-sensitive algorithms that were developed in this thesis fail to learn a trading strategy which is profitable on the backtest set, it is still remarkable that the \gls{RSNPGPE} algorithm manages to learn a strategy that is profitable on the training set while the risk-neutral algorithms could not. This indicates that there is some value in the algorithms we proposed, even if they could not succeed in the extremely difficult task of beating the market

\subsection{The Challenge of Historical Data}
In the previous sections, we presented the application of the reinforcement learning algorithms we developed in this thesis to the historical price series. In particular, we discussed how these algorithms fail to learn a trading strategy which consistently outperforms the naive Buy and Hold strategy in the backtest phase. This outcome was partly expected given the simplicity of the parametric policy considered. However, even if we considered a more complex controller, success would not be a-priori guaranteed. This is due to the inherent complexity of the financial markets. Indeed, while identifying patterns in historical data is not particularly hard, finding signals that work reliably in the real world is. Man AHL, a quant unit of Man Group Plc, needed three years of work to gain enough confidence in a machine learning strategy to devote client money to it. Therefore, it is clear that there is still much work to be done to be able to beat the markets with a strategy produced by a reinforcement learning algorithm. 

\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/8_10_single_hist_sensitive_convergence}
	\caption[Risk-sensitive learning process for the historical risky asset.]{Risk-sensitive learning process for the asset allocation problem with an historical risky asset.}
	\label{fig:8_10_rs_learning_process_historical}
\end{figure}

\begin{figure}[t!]
	\centering
	\includegraphics[height=6cm,width=1.0\textwidth]{Images/8_11_single_hist_sensitive_performance}
	\caption[Backtest performance with one historical risky asset.]{Backtest performance of the trading systems learned for the asset allocation problem with one historical risky asset.}
	\label{fig:8_11_single_hist_sensitive_performance}
\end{figure}

\begin{table}[t!]
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
                  & \multicolumn{1}{c}{Buy and Hold} & \multicolumn{1}{c}{RSPGPE} & \multicolumn{1}{c}{RSNPGPE} \\ \midrule
Total Return      & 3.29\%       & 1.70\%   & -8.12\%  \\
Daily Sharpe      & 0.48         & 0.30     & -0.93    \\
Monthly Sharpe    & -0.25        & -0.90    & 0.12     \\
Max Drawdown      & -14.68\%     & -15.65\% & -19.40\% \\
Avg Drawdown      & -6.90\%      & -8.29\%  & -9.22\%  \\
Avg Up Month      & 4.43\%       & 2.58\%   & 2.53\%   \\
Avg Down Month    & -2.65\%      & -2.77\%  & -5.15\%  \\
Reallocation Freq & 0.00\%       & 3.67\%   & 39.59\%  \\
Short Freq        & 0.00\%       & 3.10\%   & 37.80\%  \\ \bottomrule
\end{tabular}
\caption[Backtest statistics for risk-sensitive learning with one historical risky asset.]{Backtest statistics of the risk-sensitive trading strategies for the asset allocation problem with one historical risky asset.}
\label{tab:single_historical_sensitive_performance}
\end{table}
\clearpage





