\BOOKMARK [0][-]{chapter.1}{Markov Decision Processes}{}% 1
\BOOKMARK [1][-]{section.1.1}{Markov Decision Processes}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Optimal Control Problem}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Bellman Equations}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{Risk-Sensitive MDP}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.5}{Average Reward Formulation}{chapter.1}% 6
\BOOKMARK [0][-]{chapter.2}{Reinforcement Learning}{}% 7
\BOOKMARK [1][-]{section.2.1}{The Reinforcement Learning Problem}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.2}{Policy Gradient}{chapter.2}% 9
\BOOKMARK [2][-]{subsection.2.2.1}{Basics of Policy Gradient}{section.2.2}% 10
\BOOKMARK [2][-]{subsection.2.2.2}{Finite Differences}{section.2.2}% 11
\BOOKMARK [2][-]{subsection.2.2.3}{Monte Carlo Policy Gradient}{section.2.2}% 12
\BOOKMARK [2][-]{subsection.2.2.4}{Policy Gradient Theorem}{section.2.2}% 13
\BOOKMARK [2][-]{subsection.2.2.5}{Natural Policy Gradient}{section.2.2}% 14
\BOOKMARK [2][-]{subsection.2.2.6}{Policy Gradient with Parameter Exploration}{section.2.2}% 15
\BOOKMARK [0][-]{chapter.3}{Asset Allocation}{}% 16
\BOOKMARK [1][-]{section.3.1}{Reward Function}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.2}{States}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.3}{Actions}{chapter.3}% 19
