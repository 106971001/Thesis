\begin{thebibliography}{10}

\bibitem{agarwal2010optimal}
{\sc A.~Agarwal, P.~Bartlett, and M.~Dama}, {\em Optimal allocation strategies
  for the dark pool problem}, arXiv preprint arXiv:1003.2245,  (2010).

\bibitem{almgren2001optimal}
{\sc R.~Almgren and N.~Chriss}, {\em Optimal execution of portfolio
  transactions}, Journal of Risk, 3 (2001), pp.~5--40.

\bibitem{bauerle2011markov}
{\sc N.~B{\"a}uerle and U.~Rieder}, {\em Markov decision processes with
  applications to finance}, Springer Science \& Business Media, 2011.

\bibitem{bekiros2010heterogeneouseltit}
{\sc S.~D. Bekiros}, {\em Heterogeneous trading strategies with adaptive fuzzy
  actorâ€“critic reinforcement learning: A behavioral approach}, Journal of
  Economic Dynamics and Control, 34 (2010), pp.~1153--1170.

\bibitem{bertoluzzo2012testing}
{\sc F.~Bertoluzzo and M.~Corazza}, {\em Testing different reinforcement
  learning configurations for financial trading: Introduction and
  applications}, Procedia Economics and Finance, 3 (2012), pp.~68--77.

\bibitem{corazza2014q}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Q-learning-based
  financial trading systems with applications}, University Ca'Foscari of
  Venice, Dept. of Economics Working Paper Series No, 15 (2014).

\bibitem{bertoluzzo2014reinforcement}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Reinforcement
  learning for automated financial trading: Basics and applications}, in Recent
  Advances of Neural Network Models and Applications, Springer, 2014,
  pp.~197--213.

\bibitem{bertsekas1995dynamic}
{\sc D.~P. Bertsekas}, {\em Dynamic programming and optimal control}, vol.~1,
  Athena Scientific, Belmont, 1995.

\bibitem{bertsekas1996neuro}
{\sc D.~P. Bertsekas and J.~N. Tsitsiklis}, {\em Neuro-Dynamic Programming},
  Optimization and neural computation series, Athena Scientific, Belmont,
  1~ed., 1996.

\bibitem{bishop2006pattern}
{\sc C.~M. Bishop}, {\em Pattern Recognition and Machine Learning}, Springer,
  2006.

\bibitem{busoniu2010reinforcement}
{\sc L.~Busoniu, R.~Babuska, B.~De~Schutter, and D.~Ernst}, {\em Reinforcement
  learning and dynamic programming using function approximators}, vol.~39, CRC
  press, 2010.

\bibitem{casqueiro2006neuro}
{\sc P.~X. Casqueiro and A.~J. Rodrigues}, {\em Neuro-dynamic trading methods},
  European Journal of Operational Research, 175 (2006), pp.~1400--1412.

\bibitem{chapados2001cost}
{\sc N.~Chapados and Y.~Bengio}, {\em Cost functions and model combination for
  var-based asset allocation using neural networks}, IEEE Transactions on
  Neural Networks, 12 (2001), pp.~890--906.

\bibitem{choey1997nonlineareltit}
{\sc M.~Choey and A.~S. Weigend}, {\em Nonlinear trading models through sharpe
  ratio maximization}, International Journal of Neural Systems, 8 (1997),
  pp.~417--431.

\bibitem{chow2015risk}
{\sc Y.~Chow, A.~Tamar, S.~Mannor, and M.~Pavone}, {\em Risk-sensitive and
  robust decision-making: a cvar optimization approach}, in Advances in Neural
  Information Processing Systems, 2015, pp.~1522--1530.

\bibitem{corazzaq}
{\sc M.~Corazza and A.~Sangalli}, {\em Q-learning vs. sarsa: comparing two
  intelligent stochastic control approaches for financial trading}.

\bibitem{cumming2015investigation}
{\sc J.~Cumming, D.~Alrajeh, and L.~Dickens}, {\em An investigation into the
  use of reinforcement learning techniques within the algorithmic trading
  domain},  (2015).

\bibitem{dempster2006automated}
{\sc M.~A. Dempster and V.~Leemans}, {\em An automated fx trading system using
  adaptive reinforcement learning}, Expert Systems with Applications, 30
  (2006), pp.~543--552.

\bibitem{dempster2002intraday}
{\sc M.~A.~H. Dempster and Y.~S. Romahi}, {\em Intraday FX trading: An
  evolutionary reinforcement learning approach}, Springer, 2002.

\bibitem{deng2016deep}
{\sc Y.~Deng, F.~Bao, Y.~Kong, Z.~Ren, and Q.~Dai}, {\em Deep direct
  reinforcement learning for financial signal representation and trading}, IEEE
  Transactions on Neural Networks and Learning Systems,  (2016).

\bibitem{deng2015sparse}
{\sc Y.~Deng, Y.~Kong, F.~Bao, and Q.~Dai}, {\em Sparse coding inspired optimal
  trading system for hft industry}, IEEE Transactions on Industrial
  Informatics, 11 (2015), pp.~467--475.

\bibitem{du1algorithm}
{\sc X.~Du, J.~Zhai, and K.~Lv}, {\em Algorithm trading using q-learning and
  recurrent reinforcement learning}, positions, 1, p.~1.

\bibitem{eldercreating}
{\sc T.~Elder}, {\em Creating algorithmic traders with hierarchical
  reinforcement learning},  (2008).

\bibitem{feldkamp1998enhanced}
{\sc L.~A. Feldkamp, D.~V. Prokhorov, C.~F. Eagen, and F.~Yuan}, {\em Enhanced
  multi-stream kalman filter training for recurrent networks}, in Nonlinear
  Modeling, Springer, 1998, pp.~29--53.

\bibitem{ganchev2010censored}
{\sc K.~Ganchev, Y.~Nevmyvaka, M.~Kearns, and J.~W. Vaughan}, {\em Censored
  exploration and the dark pool problem}, Communications of the ACM, 53 (2010),
  pp.~99--107.

\bibitem{gold2003FX}
{\sc C.~Gold}, {\em Fx trading via recurrent reinforcement learning}, in IEEE
  2003 IEEE International Conference on Computational Intelligence for
  Financial Engineering. Proceedings, 2003.

\bibitem{Goodfellow-et-al-2016-Book}
{\sc I.~Goodfellow, Y.~Bengio, and A.~Courville}, {\em Deep learning}.
\newblock Book in preparation for MIT Press, 2016.

\bibitem{hastie2009unsupervised}
{\sc T.~Hastie, R.~Tibshirani, and J.~Friedman}, {\em The elements of
  statistical learning: data mining, inference, and prediction}, Springer,
  2009.

\bibitem{hendricks2014reinforcement}
{\sc D.~Hendricks and D.~Wilcox}, {\em A reinforcement learning extension to
  the almgren-chriss framework for optimal trade execution}, in IEEE Conference
  on Computational Intelligence for Financial Engineering \& Economics (CIFEr),
  2014, pp.~457--464.

\bibitem{jaeger2002tutorial}
{\sc H.~Jaeger}, {\em Tutorial on training recurrent neural networks, covering
  BPPT, RTRL, EKF and the echo state network approach}, GMD-Forschungszentrum
  Informationstechnik, 2002.

\bibitem{kamijo1990stock}
{\sc K.~Kamijo and T.~Tanigawa}, {\em Stock price pattern recognition-a
  recurrent neural network approach}, in IEEE 1990 IJCNN International Joint
  Conference on Neural Networks, 1990.

\bibitem{kearns2013machine}
{\sc M.~Kearns and Y.~Nevmyvaka}, {\em Machine learning for market
  microstructure and high frequency trading}, High-Frequency Trading--New
  Realities for Traders, Markets and Regulators,  (2013), pp.~91--124.

\bibitem{konda1999actor}
{\sc V.~R. Konda and J.~N. Tsitsiklis}, {\em Actor-critic algorithms.}, in
  NIPS, vol.~13, 1999, pp.~1008--1014.

\bibitem{laruelle2011optimal}
{\sc S.~Laruelle, C.-A. Lehalle, and G.~Pages}, {\em Optimal split of orders
  across liquidity pools: a stochastic algorithm approach}, SIAM Journal on
  Financial Mathematics, 2 (2011), pp.~1042--1076.

\bibitem{laruelle2013optimal}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Optimal posting
  price of limit orders: learning by trading}, Mathematics and Financial
  Economics, 7 (2013), pp.~359--403.

\bibitem{li2007short}
{\sc H.~Li, C.~H. Dagli, and D.~Enke}, {\em Short-term stock market timing
  prediction under reinforcement learning schemes}, in 2007 IEEE International
  Symposium on Approximate Dynamic Programming and Reinforcement Learning,
  2007, pp.~233--240.

\bibitem{miyamae2010natural}
{\sc A.~Miyamae, Y.~Nagata, I.~Ono, and S.~Kobayashi}, {\em Natural policy
  gradient methods with parameter-based exploration for control tasks}, in
  Advances in neural information processing systems, 2010, pp.~1660--1668.

\bibitem{moody2001learning}
{\sc J.~Moody and M.~Saffell}, {\em Learning to trade via direct
  reinforcement}, Neural Networks, IEEE Transactions on, 12 (2001),
  pp.~875--889.

\bibitem{moody2013reinforcement}
{\sc J.~Moody, M.~Saffell, Y.~Liao, and L.~Wu}, {\em Reinforcement learning for
  trading systems}, in Decision Technologies for Computational Finance:
  Proceedings of the fifth International Conference Computational Finance,
  vol.~2, Springer Science \& Business Media, 2013, p.~129.

\bibitem{moody1997optimization}
{\sc J.~Moody and L.~Wu}, {\em Optimization of trading systems and portfolios},
  in Proceedings of the IEEE/IAFE 1997 Computational Intelligence for Financial
  Engineering (CIFEr), 1997, pp.~300--307.

\bibitem{moody1998performance}
{\sc J.~Moody, L.~Wu, Y.~Liao, and M.~Saffell}, {\em Performance functions and
  reinforcement learning for trading systems and portfolios}, Journal of
  Forecasting, 17 (1998), pp.~441--470.

\bibitem{nevmyvaka2006reinforcement}
{\sc Y.~Nevmyvaka, Y.~Feng, and M.~Kearns}, {\em Reinforcement learning for
  optimized trade execution}, in Proceedings of the 23rd international
  conference on Machine learning, ACM, 2006, pp.~673--680.

\bibitem{nocedal2006numerical}
{\sc J.~Nocedal and S.~Wright}, {\em Numerical optimization}, Springer Science
  \& Business Media, 2006.

\bibitem{o2006adaptive}
{\sc J.~O, J.~Lee, J.~W. Lee, and B.-T. Zhang}, {\em Adaptive stock trading
  with dynamic asset allocation using reinforcement learning}, Information
  Sciences, 176 (2006), pp.~2121--2147.

\bibitem{peters2010relative}
{\sc J.~Peters, K.~M{\"u}lling, and Y.~Altun}, {\em Relative entropy policy
  search.}, in AAAI, Atlanta, 2010.

\bibitem{peters2006policy}
{\sc J.~Peters and S.~Schaal}, {\em Policy gradient methods for robotics}, in
  Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on,
  IEEE, 2006, pp.~2219--2225.

\bibitem{peters2008reinforcement}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Reinforcement
  learning of motor skills with policy gradients}, Neural networks, 21 (2008),
  pp.~682--697.

\bibitem{prashanth2014actor}
{\sc L.~Prashanth and M.~Ghavamzadeh}, {\em Actor-critic algorithms for
  risk-sensitive reinforcement learning.}, arXiv preprint arXiv:1403.6530,
  (2014).

\bibitem{Saad1998comparative}
{\sc E.~W. Saad, D.~V. Prokhorov, and D.~C. Wunsch}, {\em Comparative study of
  stock trend prediction using time delay, recurrent and probabilistic neural
  networks}, IEEE Transactions on Neural Networks, 9 (1998), pp.~1456--1470.

\bibitem{sato2000variance}
{\sc M.~Sato and S.~Kobayashi}, {\em Variance-penalized reinforcement learning
  for risk-averse asset allocation}, in Intelligent Data Engineering and
  Automated Learningâ€”IDEAL 2000. Data Mining, Financial Engineering, and
  Intelligent Agents, Springer, 2000, pp.~244--249.

\bibitem{sehnke2012parameter}
{\sc F.~Sehnke et~al.}, {\em Parameter exploring policy gradients and their
  implications}, PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 2012.

\bibitem{sehnke2008policy}
{\sc F.~Sehnke, C.~Osendorfer, T.~R{\"u}ckstie{\ss}, A.~Graves, J.~Peters, and
  J.~Schmidhuber}, {\em Policy gradients with parameter-based exploration for
  control}, in Artificial Neural Networks-ICANN 2008, Springer, 2008,
  pp.~387--396.

\bibitem{sehnke2010parameter}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Parameter-exploring
  policy gradients}, Neural Networks, 23 (2010), pp.~551--559.

\bibitem{silver2014deterministic}
{\sc D.~Silver, G.~Lever, N.~Heess, T.~Degris, D.~Wierstra, and M.~Riedmiller},
  {\em Deterministic policy gradient algorithms}, in ICML, 2014.

\bibitem{sutton1998introduction}
{\sc R.~S. Sutton and A.~G. Barto}, {\em Introduction to reinforcement
  learning}, vol.~135, MIT Press Cambridge, 1998.

\bibitem{sutton1999policy}
{\sc R.~S. Sutton, D.~A. McAllester, S.~P. Singh, Y.~Mansour, et~al.}, {\em
  Policy gradient methods for reinforcement learning with function
  approximation.}, in NIPS, vol.~99, 1999, pp.~1057--1063.

\bibitem{szepesvari2010algorithms}
{\sc C.~Szepesv{\'a}ri}, {\em Algorithms for reinforcement learning}, Synthesis
  lectures on artificial intelligence and machine learning, 4 (2010),
  pp.~1--103.

\bibitem{tamar2013temporal}
{\sc A.~Tamar, D.~D. Castro, and S.~Mannor}, {\em Temporal difference methods
  for the variance of the reward to go}, in Proceedings of the 30th
  International Conference on Machine Learning (ICML-13), 2013, pp.~495--503.

\bibitem{tamar2015policy}
{\sc A.~Tamar, Y.~Chow, M.~Ghavamzadeh, and S.~Mannor}, {\em Policy gradient
  for coherent risk measures}, in Advances in Neural Information Processing
  Systems, 2015, pp.~1468--1476.

\bibitem{tamar2012policy}
{\sc A.~Tamar, D.~Di~Castro, and S.~Mannor}, {\em Policy gradients with
  variance related risk criteria}, in Proceedings of the 29th International
  Conference on Machine Learning, 2012, pp.~387--396.

\bibitem{tamar2013variance}
{\sc A.~Tamar and S.~Mannor}, {\em Variance adjusted actor critic algorithms},
  arXiv preprint arXiv:1310.3697,  (2013).

\bibitem{tan2011stock}
{\sc Z.~Tan, C.~Quek, and P.~Y. Cheng}, {\em Stock trading with cycles: A
  financial application of anfis and reinforcement learning}, Expert Systems
  with Applications, 38 (2011), pp.~4741--4755.

\bibitem{tsay2005analysis}
{\sc R.~S. Tsay}, {\em Analysis of financial time series}, vol.~543, John Wiley
  \& Sons, 2005.

\bibitem{werbos1990backpropagation}
{\sc P.~J. Werbos}, {\em Backpropagation through time: what it does and how to
  do it}, Proceedings of the IEEE, 78 (1990), pp.~1550--1560.

\bibitem{wiering2012reinforcement}
{\sc M.~Wiering and M.~Van~Otterlo}, {\em Reinforcement Learning:
  State-of-the-Art}, vol.~12 of Adaptation, Learning, and Optimization,
  Springer, 1~ed., 2012.

\bibitem{williams1989learning}
{\sc R.~J. Williams and D.~Zipser}, {\em A learning algorithm for continually
  running fully recurrent neural networks}, Neural computation, 1 (1989),
  pp.~270--280.

\bibitem{Yang2012behavior}
{\sc S.~Yang, M.~Paddrik, R.~Hayes, A.~Todd, A.~Kirilenko, P.~Beling, and
  W.~Scherer}, {\em Behavior based learning in identifying high frequency
  trading strategies}, in IEEE Conference on Computational Intelligence for
  Financial Engineering \& Economics (CIFEr), 2012.

\bibitem{zhao2011analysis}
{\sc T.~Zhao, H.~Hachiya, G.~Niu, and M.~Sugiyama}, {\em Analysis and
  improvement of policy gradient estimation}, in Advances in Neural Information
  Processing Systems, 2011, pp.~262--270.

\bibitem{zhao2015regularized}
{\sc T.~Zhao, G.~Niu, N.~Xie, J.~Yang, and M.~Sugiyama}, {\em Regularized
  policy gradients: Direct variance reduction in policy gradient estimation},
  in Proceedings of The 7th Asian Conference on Machine Learning, 2015,
  pp.~333--348.

\end{thebibliography}
