\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@input{Abstract/abstract.aux}
\@input{Acknowledgements/acknowledgements.aux}
\citation{lewis2014flash}
\citation{brogaard2014high}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The Computerization of Finance}{1}{section.1.1}}
\citation{economist2016march}
\citation{silver2016mastering}
\citation{bloomberg2016ml}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}The New Dawn of Artificial Intelligence}{2}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure}{3}{section.1.3}}
\citation{bertsekas1978stochastic}
\citation{puterman1994markov}
\citation{bertsekas1995dynamic}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Discrete-Time Stochastic Optimal Control}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:discrete_time_stochastic_optimal_control}{{2}{5}{Discrete-Time Stochastic Optimal Control}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Markov Decision Processes}{5}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Agent-environment interaction in sequential decision problems.\relax }}{6}{figure.caption.11}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sequential_decision_problem}{{2.1}{6}{Agent-environment interaction in sequential decision problems.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Policies}{6}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Risk-Neutral Framework}{7}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Discounted Reward Formulation}{8}{subsection.2.3.1}}
\newlabel{eq:bellman_expectation_eq_V}{{2.6}{9}{Bellman Expectation Equations}{equation.2.3.6}{}}
\newlabel{eq:bellman_expectation_eq_Q}{{2.7}{9}{Bellman Expectation Equations}{equation.2.3.7}{}}
\citation{arapostathis1993discrete}
\citation{mahadevan1996average}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Average Reward Formulation}{10}{subsection.2.3.2}}
\newlabel{eq:VQ_equality}{{2.18}{11}{Average Reward Formulation}{equation.2.3.18}{}}
\citation{sobel1982variance}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Risk-Sensitive Framework}{12}{section.2.4}}
\newlabel{sec:risk_sensitive_formulation}{{2.4}{12}{Risk-Sensitive Framework}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Discounted Reward Formulation}{12}{subsection.2.4.1}}
\newlabel{eq:variance_decomposition}{{2.22}{12}{Discounted Reward Formulation}{equation.2.4.22}{}}
\citation{tamar2012policy}
\citation{prashanth2014actor}
\citation{prashanth2014actor}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Average Reward Formulation}{15}{subsection.2.4.2}}
\citation{littman1996algorithms}
\citation{szepesvari2010algorithms}
\newlabel{eq:UW_equality}{{2.45}{16}{Average Reward Formulation}{equation.2.4.45}{}}
\newlabel{eq:risk_sensitive_problem}{{2.48}{16}{Average Reward Formulation}{equation.2.4.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Dynamic Programming Algorithms}{16}{section.2.5}}
\newlabel{sec:policy_evaluation}{{2.5}{16}{Dynamic Programming Algorithms}{section.2.5}{}}
\citation{sutton1998introduction}
\citation{sutton1998introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Policy iteration algorithm}}{17}{figure.caption.12}}
\newlabel{fig:policy_iteration}{{2.2}{17}{Policy iteration algorithm}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Value Iteration}{17}{subsection.2.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Policy Iteration}{17}{subsection.2.5.2}}
\citation{sutton1998introduction}
\citation{szepesvari2010algorithms}
\citation{wiering2012reinforcement}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Reinforcement Learning}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:reinforcement_learning}{{3}{19}{Reinforcement Learning}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The Reinforcement Learning Problem}{19}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Model-Free RL Methods}{20}{section.3.2}}
\citation{wiering2012reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Solution process for the control problem.\relax }}{21}{figure.caption.13}}
\newlabel{fig:control_dependences}{{3.1}{21}{Solution process for the control problem.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Model Approximation}{21}{subsection.3.2.1}}
\citation{sutton1999policy}
\citation{konda1999actor}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Value Approximation}{22}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Policy Approximation}{22}{subsection.3.2.3}}
\citation{peters2008reinforcement}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Risk-Neutral Policy Gradient}{23}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:policy_gradient}{{4}{23}{Risk-Neutral Policy Gradient}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Basics of Policy Gradient Methods}{23}{section.4.1}}
\citation{kushner2003stochastic}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces General setup for a policy gradient algorithm.\relax }}{24}{algorithm.4.1}}
\newlabel{algo:policy_gradient}{{4.1}{24}{General setup for a policy gradient algorithm.\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Risk-Neutral Objective Functions}{24}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Finite Differences}{25}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Likelihood Ratio Methods}{25}{section.4.4}}
\citation{pages2016introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Monte Carlo Policy Gradient}{26}{subsection.4.4.1}}
\newlabel{sec:MCPG}{{4.4.1}{26}{Monte Carlo Policy Gradient}{subsection.4.4.1}{}}
\newlabel{eq:gradient_MC}{{4.9}{27}{Monte Carlo Policy Gradient}{equation.4.4.9}{}}
\newlabel{eq:likelihood_bias}{{4.11}{27}{Monte Carlo Policy Gradient}{equation.4.4.11}{}}
\newlabel{eq:gradient_MC_baseline}{{4.12}{27}{Monte Carlo Policy Gradient}{equation.4.4.12}{}}
\newlabel{eq:reinforce_gradient}{{4.13}{27}{Monte Carlo Policy Gradient}{equation.4.4.13}{}}
\citation{baxter2001infinite}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces Episodic REINFORCE policy gradient estimate\relax }}{28}{algorithm.4.2}}
\newlabel{algo:reinforce}{{4.2}{28}{Episodic REINFORCE policy gradient estimate\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1.1}Optimal Baseline}{28}{subsubsection.4.4.1.1}}
\newlabel{eq:optimal_baseline}{{4.15}{28}{Optimal Baseline}{equation.4.4.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}GPOMDP}{28}{subsection.4.4.2}}
\newlabel{eq:GPOMDP}{{4.16}{29}{GPOMDP}{equation.4.4.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Stochastic Policies}{29}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3.1}Boltzmann Exploration Policy}{29}{subsubsection.4.4.3.1}}
\newlabel{sec:softmax}{{4.4.3.1}{29}{Boltzmann Exploration Policy}{subsubsection.4.4.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3.2}Gaussian Exploration Policy}{29}{subsubsection.4.4.3.2}}
\newlabel{sec:gaussian_policy}{{4.4.3.2}{29}{Gaussian Exploration Policy}{subsubsection.4.4.3.2}{}}
\citation{sehnke2008policy}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Policy Gradient with Parameter Exploration}{30}{subsection.4.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4.1}Episodic PGPE}{30}{subsubsection.4.4.4.1}}
\citation{zhao2011analysis}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.3}{\ignorespaces Episodic PGPE algorithm\relax }}{31}{algorithm.4.3}}
\newlabel{algo:episodic_pgpe}{{4.3}{31}{Episodic PGPE algorithm\relax }{algorithm.4.3}{}}
\newlabel{eq:pgpe_gradient}{{4.24}{31}{Episodic PGPE}{equation.4.4.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Independent Gaussian Parameter Distribution}{31}{section*.14}}
\@writefile{toc}{\contentsline {paragraph}{Gaussian Parameter Distribution}{32}{section*.15}}
\@writefile{toc}{\contentsline {paragraph}{Symmetric Sampling and Gain Normalization}{32}{section*.16}}
\citation{sehnke2012parameter}
\citation{sutton1999policy}
\citation{konda1999actor}
\citation{sutton1999policy}
\citation{kakade2001natural}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4.2}Infinite Horizon PGPE}{33}{subsubsection.4.4.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Risk-Neutral Policy Gradient Theorem}{33}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Theorem Statement and Proof}{34}{subsection.4.5.1}}
\newlabel{thm:risk_neutral_policy_gradient}{{4.5.1}{34}{Risk-Neutral Policy Gradient}{theorem.4.5.1}{}}
\newlabel{eq:pg_theorem_baseline}{{4.36}{36}{Theorem Statement and Proof}{equation.4.5.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}GPOMDP}{36}{subsection.4.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Actor-Critic Policy Gradient}{36}{subsection.4.5.3}}
\newlabel{eq:actor_critic_pg}{{4.37}{36}{Actor-Critic Policy Gradient}{equation.4.5.37}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.4}{\ignorespaces Generic structure for an online actor-critic algorithm.\relax }}{37}{algorithm.4.4}}
\newlabel{algo:actor_critic}{{4.4}{37}{Generic structure for an online actor-critic algorithm.\relax }{algorithm.4.4}{}}
\citation{sutton1999policy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.5}{\ignorespaces TD($\lambda $) policy gradient algorithm.\relax }}{38}{algorithm.4.5}}
\newlabel{algo:actor_critic_td}{{4.5}{38}{TD($\lambda $) policy gradient algorithm.\relax }{algorithm.4.5}{}}
\newlabel{eq:td_error}{{4.41}{38}{Actor-Critic Policy Gradient}{equation.4.5.41}{}}
\citation{kakade2001natural}
\citation{peters2008reinforcement}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Compatible Function Approximation}{39}{subsection.4.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Natural Policy Gradient}{39}{subsection.4.5.5}}
\citation{peters2008reinforcement}
\citation{peters2008reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces ``Vanilla'' policy gradient vs. natural policy gradient}}{40}{figure.caption.17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.5.1}Formalism of Natural Policy Gradients}{40}{subsubsection.4.5.5.1}}
\citation{miyamae2010natural}
\citation{tamar2012policy}
\citation{prashanth2014actor}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Risk-Sensitive Policy Gradient}{43}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:risk_sensitive_policy_gradient}{{5}{43}{Risk-Sensitive Policy Gradient}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Risk-Sensitive Framework}{43}{section.5.1}}
\citation{markowitz1952portfolio}
\citation{sharpe1994sharpe}
\citation{tamar2012policy}
\newlabel{eq:gradient_mean_variance}{{5.6}{44}{Risk-Sensitive Framework}{equation.5.1.6}{}}
\newlabel{eq:gradient_sharpe_ratio}{{5.8}{44}{Risk-Sensitive Framework}{equation.5.1.8}{}}
\citation{tamar2013temporal}
\citation{tamar2013variance}
\citation{tamar2015policy}
\citation{chow2015risk}
\citation{prashanth2014actor}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Monte Carlo Policy Gradient}{45}{section.5.2}}
\newlabel{eq:reinforce_gradient_2}{{5.12}{45}{Monte Carlo Policy Gradient}{equation.5.2.12}{}}
\newlabel{eq:optimal_baseline_2}{{5.14}{45}{Monte Carlo Policy Gradient}{equation.5.2.14}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5.1}{\ignorespaces Risk-sensitive REINFORCE policy gradient estimate\relax }}{46}{algorithm.5.1}}
\newlabel{algo:RSreinforce}{{5.1}{46}{Risk-sensitive REINFORCE policy gradient estimate\relax }{algorithm.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Policy Gradient Theorem}{46}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Average Reward Formulation}{47}{subsection.5.3.1}}
\newlabel{eq:policy_gradient_theorem_W}{{5.19}{47}{Risk-Sensitive Policy Gradient}{equation.5.3.19}{}}
\citation{prashanth2014actor}
\newlabel{eq:pg_advantage_W}{{5.21}{48}{Average Reward Formulation}{equation.5.3.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Risk-Sensitive Actor-Critic Algorithm}{48}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Discounted Reward Formulation}{49}{subsection.5.3.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5.2}{\ignorespaces Risk-Sensitive Average Reward Actor-Critic algorithm\relax }}{50}{algorithm.5.2}}
\newlabel{algo:RSARAC}{{5.2}{50}{Risk-Sensitive Average Reward Actor-Critic algorithm\relax }{algorithm.5.2}{}}
\citation{miyamae2010natural}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Parameter-Based Policy Gradient}{53}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:parameter_based_policy_gradient}{{6}{53}{Parameter-Based Policy Gradient}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Risk-Neutral Framework}{53}{section.6.1}}
\newlabel{eq:policy_gradient}{{6.1}{54}{Risk-Neutral Framework}{equation.6.1.2}{}}
\citation{miyamae2010natural}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Parameter-Based Natural Policy Gradient}{55}{subsection.6.1.1}}
\citation{sun2009efficient}
\citation{akimoto2010bidirectional}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6.1}{\ignorespaces Actor-Critic PGPE\relax }}{56}{algorithm.6.1}}
\newlabel{algo:ACPGPE}{{6.1}{56}{Actor-Critic PGPE\relax }{algorithm.6.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6.2}{\ignorespaces NPGPE\relax }}{58}{algorithm.6.2}}
\newlabel{algo:NPGPE}{{6.2}{58}{NPGPE\relax }{algorithm.6.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6.3}{\ignorespaces Natural Actor-Critic PGPE\relax }}{59}{algorithm.6.3}}
\newlabel{algo:NACPGPE}{{6.3}{59}{Natural Actor-Critic PGPE\relax }{algorithm.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Risk-Sensitive Framework}{60}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Parameter-Based Natural Policy Gradient}{60}{subsection.6.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6.4}{\ignorespaces Risk-Sensitive NPGPE\relax }}{61}{algorithm.6.4}}
\newlabel{algo:RSNPGPE}{{6.4}{61}{Risk-Sensitive NPGPE\relax }{algorithm.6.4}{}}
\citation{timmermann2004efficient}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Financial Applications of Reinforcement Learning}{63}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:financial_applications_of_reinforcement_learning}{{7}{63}{Financial Applications of Reinforcement Learning}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Efficient Market Hypothesis}{63}{section.7.1}}
\newlabel{sec:efficient_market_hypothesis}{{7.1}{63}{Efficient Market Hypothesis}{section.7.1}{}}
\citation{jensen1978some}
\citation{malkiel1970efficient}
\citation{fama1991efficient}
\citation{malkiel2003efficient}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Formal Definitions of the EMH}{64}{subsection.7.1.1}}
\citation{mallaby2010more}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Critics to the EMH}{65}{subsection.7.1.2}}
\citation{lo2000foundations}
\citation{Goodfellow-et-al-2016-Book}
\citation{kamijo1990stock}
\citation{saad1998comparative}
\citation{liang2011stock}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Bibliographical Survey}{66}{section.7.2}}
\newlabel{sec:bibliographical_survey}{{7.2}{66}{Bibliographical Survey}{section.7.2}{}}
\citation{moody1997optimization}
\citation{jaeger2002tutorial}
\citation{werbos1990backpropagation}
\citation{williams1989learning}
\citation{moody2001learning}
\citation{choey1997nonlineareltit}
\citation{chapados2001cost}
\citation{gold2003FX}
\citation{casqueiro2006neuro}
\citation{dempster2006automated}
\citation{li2007short}
\citation{deng2016deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Asset Allocation with Transaction Costs}{67}{subsection.7.2.1}}
\citation{almgren2001optimal}
\citation{johnson2010algorithmic}
\citation{nevmyvaka2006reinforcement}
\citation{hendricks2014reinforcement}
\citation{almgren2001optimal}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Optimal Order Execution in Limit Order Book}{68}{subsection.7.2.2}}
\citation{cartea2015algorithmic}
\citation{ganchev2010censored}
\citation{gittins2011multi}
\citation{kearns2013machine}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Smart Order Routing Across Dark Pools}{69}{subsection.7.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Asset Allocation with Transaction Costs}{70}{section.7.3}}
\newlabel{sec:asset_allocation_with_transaction_costs}{{7.3}{70}{Asset Allocation with Transaction Costs}{section.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Wealth Dynamics}{70}{subsection.7.3.1}}
\newlabel{eq:portfolio_return}{{7.1}{70}{Wealth Dynamics}{equation.7.3.1}{}}
\newlabel{eq:portfolio_return_benchmark}{{7.3}{71}{Wealth Dynamics}{equation.7.3.3}{}}
\citation{browne1995optimal}
\newlabel{eq:portfolio_daily_logreturn}{{7.5}{72}{Wealth Dynamics}{equation.7.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Rewards and Objective Functions}{72}{subsection.7.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2.1}Infinite Horizon Task}{72}{subsubsection.7.3.2.1}}
\citation{moody1997optimization}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2.2}Episodic Task}{73}{subsubsection.7.3.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}States}{73}{subsection.7.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Episodic formulation for the asset allocation problem.\relax }}{74}{figure.caption.18}}
\newlabel{fig:episodic_asset_alloc}{{7.1}{74}{Episodic formulation for the asset allocation problem.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.4}Actions}{74}{subsection.7.3.4}}
\citation{moody1998performance}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Numerical Results for the Asset Allocation Problem}{77}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:numerical_results}{{8}{77}{Numerical Results for the Asset Allocation Problem}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Synthetic Risky Asset}{77}{section.8.1}}
\newlabel{sec:synthetic_risky_asset}{{8.1}{77}{Synthetic Risky Asset}{section.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Specifications of the Learning Algorithms}{78}{subsection.8.1.1}}
\@writefile{toc}{\contentsline {paragraph}{ARAC}{78}{section*.19}}
\@writefile{toc}{\contentsline {paragraph}{PGPE}{78}{section*.20}}
\@writefile{toc}{\contentsline {paragraph}{NPGPE}{78}{section*.21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Experimental Setup}{78}{subsection.8.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Risk-neutral learning process for one synthetic risky asset}}{79}{figure.caption.22}}
\newlabel{fig:single_synthetic_neutral_convergence}{{8.1}{79}{Risk-neutral learning process for one synthetic risky asset}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Risk-Neutral Framework}{79}{subsection.8.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3.1}Convergence}{79}{subsubsection.8.1.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3.2}Performances}{79}{subsubsection.8.1.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Backtest performance with one synthetic risky asset}}{80}{figure.caption.23}}
\newlabel{fig:single_synthetic_neutral_performance}{{8.2}{80}{Backtest performance with one synthetic risky asset}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3.3}Impact of Transaction Costs}{80}{subsubsection.8.1.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Backtest statistics for risk-neutral learning with one synthetic risky asset}}{81}{table.caption.24}}
\newlabel{tab:single_synthetic_neutral_performance}{{8.1}{81}{Backtest statistics for risk-neutral learning with one synthetic risky asset}{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces Proportional transaction costs and risk-neutral strategies}}{82}{figure.caption.25}}
\newlabel{fig:impact_transaction_costs}{{8.3}{82}{Proportional transaction costs and risk-neutral strategies}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Short-selling fees and risk-neutral strategies}}{82}{figure.caption.26}}
\newlabel{fig:impact_short_selling_fees}{{8.4}{82}{Short-selling fees and risk-neutral strategies}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Risk-Sensitive Framework}{82}{subsection.8.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces Risk-sensitive learning process for one synthetic risky asset}}{83}{figure.caption.27}}
\newlabel{fig:single_synthetic_sensitive_convergence}{{8.5}{83}{Risk-sensitive learning process for one synthetic risky asset}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Backtest performance with one synthetic risky asset}}{84}{figure.caption.28}}
\newlabel{fig:single_synthetic_sensitive_performance}{{8.6}{84}{Backtest performance with one synthetic risky asset}{figure.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.2}{\ignorespaces Backtest statistics for risk-sensitive learning with one synthetic risky asset}}{84}{table.caption.29}}
\newlabel{tab:single_synthetic_sensitive_performance}{{8.2}{84}{Backtest statistics for risk-sensitive learning with one synthetic risky asset}{table.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.3}{\ignorespaces Comparison of NPGPE and RSNPGPE for the asset allocation problem with one synthetic risky asset.\relax }}{85}{table.caption.30}}
\newlabel{tab:omparison_NPGPE}{{8.3}{85}{Comparison of NPGPE and RSNPGPE for the asset allocation problem with one synthetic risky asset.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.4.1}Risk-Neutral vs. Risk-Sensitive}{85}{subsubsection.8.1.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.4.2}Impact of Transaction Costs}{85}{subsubsection.8.1.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces Proportional transaction costs and risk-sensitive strategies}}{86}{figure.caption.31}}
\newlabel{fig:8_6_impact_transaction_costs_RS}{{8.7}{86}{Proportional transaction costs and risk-sensitive strategies}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces Short-selling fees and risk-sensitive strategies}}{86}{figure.caption.32}}
\newlabel{fig:8_7_impact_short_selling_fees_RS}{{8.8}{86}{Short-selling fees and risk-sensitive strategies}{figure.caption.32}{}}
\newlabel{fig:}{{8.9}{87}{}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Historic Risky Asset}{87}{section.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Multiple Synthetic Risky Assets}{87}{section.8.3}}
\newlabel{fig:}{{8.10}{88}{}{figure.caption.34}{}}
\newlabel{fig:}{{8.11}{88}{}{figure.caption.35}{}}
\newlabel{fig:}{{8.12}{88}{}{figure.caption.36}{}}
\newlabel{eq:sde}{{8.2}{89}{Multiple Synthetic Risky Assets}{equation.8.3.2}{}}
\newlabel{eq:sol_sde}{{8.3}{89}{Multiple Synthetic Risky Assets}{equation.8.3.3}{}}
\newlabel{eq:dt_dynamics}{{8.9}{90}{Multiple Synthetic Risky Assets}{equation.8.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Specifications of the Learning Algorithms}{90}{subsection.8.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces Sample paths for the risky assets with a mean-reverting spread.}}{91}{figure.caption.37}}
\newlabel{fig:cointegrated_series}{{8.13}{91}{Sample paths for the risky assets with a mean-reverting spread}{figure.caption.37}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Conclusions}{93}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conlusions}{{9}{93}{Conclusions}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Summary}{93}{section.9.1}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Further Developments}{93}{section.9.2}}
\citation{pybrain2010jmlr}
\@writefile{toc}{\contentsline {chapter}{Appendices}{95}{section*.38}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Implementation}{95}{Appendix.1.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Python Prototype}{95}{section.1.A.1}}
\newlabel{sec:python_prototype}{{A.1}{95}{Python Prototype}{section.1.A.1}{}}
\citation{joshi2008c++}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces PyBrain standard architecture for an RL problem.\relax }}{96}{figure.caption.39}}
\newlabel{fig:pybrain}{{A.1}{96}{PyBrain standard architecture for an RL problem.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}C++ Implementation}{96}{section.1.A.2}}
\newlabel{sec:c++_implementation}{{A.2}{96}{C++ Implementation}{section.1.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}\lstinline {Environment}, \lstinline {Task}, \lstinline {Agent} and \lstinline {Experiment}}{97}{subsection.1.A.2.1}}
\newlabel{RF1}{98}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Class architecture for the asset allocation problem.}}{98}{figure.caption.40}}
\newlabel{fig:class_architecture_base}{{A.2}{98}{Class architecture for the asset allocation problem}{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}\lstinline {ARACAgent}}{99}{subsection.1.A.2.2}}
\newlabel{RF2}{101}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Class architecture for an ARAC agent}}{101}{figure.caption.41}}
\newlabel{fig:class_architecture_arac}{{A.3}{101}{Class architecture for an ARAC agent}{figure.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Execution Pipeline}{102}{section.1.A.3}}
\newlabel{sec:execution_pipeline}{{A.3}{102}{Execution Pipeline}{section.1.A.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Compilation}{102}{subsection.1.A.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}\lstinline {generate_synthetic_series.py}}{102}{subsection.1.A.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.3}\lstinline {experiment_launcher.py}}{102}{subsection.1.A.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.4}\lstinline {main_thesis}}{102}{subsection.1.A.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.5}\lstinline {postprocessing.py}}{103}{subsection.1.A.3.5}}
\newlabel{RF3}{104}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Execution pipeline of an asset allocation experiment}}{104}{figure.caption.42}}
\newlabel{fig:pybrain}{{A.4}{104}{Execution pipeline of an asset allocation experiment}{figure.caption.42}{}}
\citation{*}
\bibstyle{siam}
\bibdata{Bibliography/bibliography}
\bibcite{agarwal2010optimal}{1}
\bibcite{akimoto2010bidirectional}{2}
\bibcite{almgren2001optimal}{3}
\bibcite{arapostathis1993discrete}{4}
\bibcite{basu2008learning}{5}
\bibcite{bauerle2011markov}{6}
\bibcite{baxter2001infinite}{7}
\bibcite{bekiros2010heterogeneouseltit}{8}
\bibcite{bertoluzzo2012testing}{9}
\bibcite{corazza2014q}{10}
\bibcite{bertoluzzo2014reinforcement}{11}
\bibcite{bertsekas1995dynamic}{12}
\bibcite{bertsekas1978stochastic}{13}
\bibcite{bertsekas1996neuro}{14}
\bibcite{bhatnagar2009natural}{15}
\bibcite{bishop2006pattern}{16}
\bibcite{borkar2001sensitivity}{17}
\bibcite{borkar2002q}{18}
\bibcite{borkar2002risk}{19}
\bibcite{brogaard2014high}{20}
\bibcite{browne1995optimal}{21}
\bibcite{browne1999reaching}{22}
\bibcite{busoniu2010reinforcement}{23}
\bibcite{cartea2015algorithmic}{24}
\bibcite{casqueiro2006neuro}{25}
\bibcite{chapados2001cost}{26}
\bibcite{choey1997nonlineareltit}{27}
\bibcite{chow2015risk}{28}
\bibcite{corazzaq}{29}
\bibcite{cumming2015investigation}{30}
\bibcite{dempster2006automated}{31}
\bibcite{dempster2002intraday}{32}
\bibcite{deng2016deep}{33}
\bibcite{deng2015sparse}{34}
\bibcite{economist2016march}{35}
\bibcite{economist2016return}{36}
\bibcite{eldercreating}{37}
\bibcite{fama1991efficient}{38}
\bibcite{feldkamp1998enhanced}{39}
\bibcite{ganchev2010censored}{40}
\bibcite{gittins2011multi}{41}
\bibcite{gold2003FX}{42}
\bibcite{Goodfellow-et-al-2016-Book}{43}
\bibcite{hastie2009unsupervised}{44}
\bibcite{hendricks2014reinforcement}{45}
\bibcite{jaeger2002tutorial}{46}
\bibcite{jensen1978some}{47}
\bibcite{johnson2010algorithmic}{48}
\bibcite{joshi2008c++}{49}
\bibcite{kakade2001natural}{50}
\bibcite{kakade2001optimizing}{51}
\bibcite{kamijo1990stock}{52}
\bibcite{kearns2013machine}{53}
\bibcite{konda1999actor}{54}
\bibcite{bloomberg2016ml}{55}
\bibcite{kushner2003stochastic}{56}
\bibcite{NIPS2013_4917}{57}
\bibcite{laruelle2011optimal}{58}
\bibcite{laruelle2013optimal}{59}
\bibcite{lewis2014flash}{60}
\bibcite{li2007short}{61}
\bibcite{liang2011stock}{62}
\bibcite{littman1996algorithms}{63}
\bibcite{lo2000foundations}{64}
\bibcite{mahadevan1996average}{65}
\bibcite{malkiel2003efficient}{66}
\bibcite{malkiel1970efficient}{67}
\bibcite{mallaby2010more}{68}
\bibcite{markowitz1952portfolio}{69}
\bibcite{miyamae2010natural}{70}
\bibcite{moody2001learning}{71}
\bibcite{moody2013reinforcement}{72}
\bibcite{moody1997optimization}{73}
\bibcite{moody1998performance}{74}
\bibcite{nevmyvaka2006reinforcement}{75}
\bibcite{nocedal2006numerical}{76}
\bibcite{o2006adaptive}{77}
\bibcite{pages2016introduction}{78}
\bibcite{peters2010relative}{79}
\bibcite{peters2006policy}{80}
\bibcite{peters2008reinforcement}{81}
\bibcite{prashanth2014actor}{82}
\bibcite{puterman1994markov}{83}
\bibcite{bloomberg2016hft}{84}
\bibcite{saad1998comparative}{85}
\bibcite{sanderson2010armadillo}{86}
\bibcite{sato2000variance}{87}
\bibcite{Sato:2001:ARL:645530.757778}{88}
\bibcite{pybrain2010jmlr}{89}
\bibcite{sehnke2012parameter}{90}
\bibcite{sehnke2008policy}{91}
\bibcite{sehnke2010parameter}{92}
\bibcite{sharpe1994sharpe}{93}
\bibcite{silver2016mastering}{94}
\bibcite{silver2014deterministic}{95}
\bibcite{sobel1982variance}{96}
\bibcite{sun2009efficient}{97}
\bibcite{sutton1998introduction}{98}
\bibcite{sutton1999policy}{99}
\bibcite{szepesvari2010algorithms}{100}
\bibcite{tamar2013temporal}{101}
\bibcite{tamar2015policy}{102}
\bibcite{tamar2012policy}{103}
\bibcite{tamar2013variance}{104}
\bibcite{tan2011stock}{105}
\bibcite{timmermann2004efficient}{106}
\bibcite{tsay2005analysis}{107}
\bibcite{werbos1990backpropagation}{108}
\bibcite{wiering2012reinforcement}{109}
\bibcite{williams1989learning}{110}
\bibcite{Yang2012behavior}{111}
\bibcite{zhao2011analysis}{112}
\bibcite{zhao2015regularized}{113}
